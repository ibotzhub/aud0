<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AUDIO FORENSICS PRO // Complete Neural Analysis Matrix</title>
    <style>
        @import url('https://fonts.googleapis.com/css2?family=JetBrains+Mono:wght@300;400;700&family=Space+Grotesk:wght@400;500;700&family=Orbitron:wght@400;700;900&display=swap');
        
        :root {
            --primary: #00ff88;
            --secondary: #88ffaa;
            --accent: #ff6b6b;
            --success: #64ff64;
            --error: #ff6b6b;
            --warning: #ffa500;
            --info: #64d8ff;
            --purple: #b794f6;
            --bg-dark: #0a0a0a;
            --bg-mid: #1a1a2e;
            --bg-light: #16213e;
            --text-primary: #ffffff;
            --text-secondary: #b3b3b3;
            --border: rgba(255, 255, 255, 0.1);
            --panel-bg: rgba(0, 0, 0, 0.6);
            
            /* Analysis Colors */
            --psych-color: #ff6b6b;
            --narrative-color: #64d8ff;
            --technical-color: #00ff88;
            --cultural-color: #b794f6;
            --gaming-color: #ffa500;
        }
        
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: 'Space Grotesk', sans-serif;
            background: linear-gradient(135deg, var(--bg-dark) 0%, var(--bg-mid) 50%, var(--bg-light) 100%);
            color: var(--text-primary);
            min-height: 100vh;
            overflow-x: hidden;
        }
        
        .container {
            max-width: 1800px;
            margin: 0 auto;
            padding: 20px;
        }
        
        /* Header */
        .header {
            text-align: center;
            margin-bottom: 40px;
            padding: 40px;
            background: var(--panel-bg);
            backdrop-filter: blur(20px);
            border-radius: 20px;
            border: 2px solid var(--primary);
            position: relative;
            overflow: hidden;
        }
        
        .header::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: conic-gradient(transparent, rgba(0, 255, 136, 0.1), transparent);
            animation: rotate 15s linear infinite;
        }
        
        @keyframes rotate {
            to { transform: rotate(360deg); }
        }
        
        .header-content {
            position: relative;
            z-index: 2;
        }
        
        .header h1 {
            font-family: 'Orbitron', monospace;
            font-size: 3.5em;
            font-weight: 900;
            margin-bottom: 15px;
            background: linear-gradient(45deg, var(--primary), var(--info), var(--purple));
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
        }
        
        .header .subtitle {
            font-size: 1.2em;
            color: var(--text-secondary);
            margin-bottom: 20px;
        }
        
        /* Upload Zone */
        .upload-zone {
            border: 3px dashed var(--primary);
            border-radius: 25px;
            padding: 60px;
            text-align: center;
            margin-bottom: 50px;
            background: var(--panel-bg);
            backdrop-filter: blur(15px);
            transition: all 0.4s ease;
        }
        
        .upload-zone.hidden,
        .upload-zone[hidden],
        .upload-zone[style*="display: none"] {
            display: none !important;
            visibility: hidden !important;
            opacity: 0 !important;
            height: 0 !important;
            overflow: hidden !important;
            margin: 0 !important;
            padding: 0 !important;
        }
        
        .upload-zone:hover,
        .upload-zone.dragover {
            border-color: var(--info);
            background: rgba(100, 216, 255, 0.1);
            transform: translateY(-5px);
        }

        .upload-zone.analyzing {
            border-color: var(--success);
            background: rgba(100, 255, 100, 0.1);
            animation: pulse 2s infinite;
        }

        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        
        .upload-btn {
            background: linear-gradient(135deg, var(--primary), var(--info));
            color: var(--bg-dark);
            padding: 18px 40px;
            border: none;
            border-radius: 15px;
            cursor: pointer;
            font-family: 'Orbitron', monospace;
            font-weight: 700;
            font-size: 1.1em;
            text-transform: uppercase;
            transition: all 0.3s ease;
        }
        
        .upload-btn:hover:not(:disabled) {
            transform: translateY(-3px);
            box-shadow: 0 15px 30px rgba(0, 255, 136, 0.4);
        }
        
        .upload-btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        #goBtn {
            font-size: 1.3em;
            padding: 20px 60px;
            background: linear-gradient(135deg, var(--success), var(--primary));
            animation: pulse-glow 2s infinite;
        }
        
        #goBtn:not(:disabled):hover {
            transform: translateY(-5px) scale(1.05);
            box-shadow: 0 20px 40px rgba(0, 255, 136, 0.6);
        }
        
        @keyframes pulse-glow {
            0%, 100% { box-shadow: 0 0 20px rgba(0, 255, 136, 0.5); }
            50% { box-shadow: 0 0 30px rgba(0, 255, 136, 0.8); }
        }
        
        /* Main Layout */
        .main-layout {
            display: none;
            grid-template-columns: 1fr 400px;
            gap: 30px;
        }
        
        .main-layout.active {
            display: grid;
        }
        
        /* Ensure canvases are visible even when parent is hidden initially */
        .viz-canvas {
            min-width: 100%;
            min-height: 300px;
        }
        
        .primary-content {
            display: grid;
            gap: 30px;
        }
        
        .sidebar {
            display: grid;
            gap: 20px;
            height: fit-content;
        }
        
        /* Panels */
        .panel {
            background: var(--panel-bg);
            border-radius: 20px;
            padding: 30px;
            backdrop-filter: blur(15px);
            border: 2px solid var(--border);
            transition: all 0.3s ease;
        }
        
        .panel:hover {
            border-color: var(--primary);
            box-shadow: 0 10px 30px rgba(0, 255, 136, 0.2);
        }
        
        .panel-header {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin-bottom: 25px;
        }
        
        .panel-title {
            font-family: 'Orbitron', monospace;
            font-size: 1.4em;
            font-weight: 700;
            color: var(--primary);
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .help-btn {
            width: 24px;
            height: 24px;
            border-radius: 50%;
            background: var(--primary);
            color: var(--bg-dark);
            border: none;
            cursor: pointer;
            font-weight: bold;
            font-size: 0.8em;
            position: relative;
            transition: all 0.2s ease;
        }
        
        .help-btn:hover {
            transform: scale(1.1);
            box-shadow: 0 0 15px var(--primary);
        }
        
        /* Tooltip */
        .tooltip {
            position: absolute;
            bottom: 35px;
            right: 0;
            background: var(--bg-dark);
            color: var(--text-primary);
            padding: 15px;
            border-radius: 10px;
            border: 1px solid var(--primary);
            max-width: 250px;
            font-size: 0.85em;
            line-height: 1.4;
            z-index: 1000;
            opacity: 0;
            visibility: hidden;
            transform: translateY(10px);
            transition: all 0.3s ease;
        }
        
        .tooltip.show {
            opacity: 1;
            visibility: visible;
            transform: translateY(0);
        }
        
        /* Audio Player Section */
        .player-section {
            background: var(--panel-bg);
            border-radius: 20px;
            padding: 25px;
            border: 2px solid var(--technical-color);
        }
        
        .audio-controls {
            margin-bottom: 25px;
        }
        
        .audio-controls audio {
            width: 100%;
            margin-bottom: 20px;
            border-radius: 10px;
        }
        
        .metadata-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(140px, 1fr));
            gap: 15px;
            margin-bottom: 20px;
        }
        
        .metadata-card {
            background: rgba(0, 255, 136, 0.1);
            border: 1px solid var(--technical-color);
            border-radius: 12px;
            padding: 12px;
            text-align: center;
        }
        
        .metadata-label {
            font-size: 0.7em;
            color: var(--text-secondary);
            text-transform: uppercase;
            letter-spacing: 1px;
            margin-bottom: 5px;
        }
        
        .metadata-value {
            font-family: 'JetBrains Mono', monospace;
            font-size: 1em;
            font-weight: 700;
            color: var(--technical-color);
        }
        
        /* Real-time Scores */
        .scores-grid {
            display: grid;
            grid-template-columns: 1fr 1fr 1fr;
            gap: 15px;
        }
        
        .score-card {
            background: var(--panel-bg);
            border-radius: 15px;
            padding: 15px;
            text-align: center;
            border: 2px solid;
        }
        
        .score-card.flow { border-color: var(--primary); }
        .score-card.tension { border-color: var(--accent); }
        .score-card.complexity { border-color: var(--warning); }
        
        .score-number {
            font-family: 'Orbitron', monospace;
            font-size: 2em;
            font-weight: 900;
            margin-bottom: 5px;
        }
        
        .score-label {
            font-size: 0.7em;
            text-transform: uppercase;
            letter-spacing: 1px;
            color: var(--text-secondary);
        }
        
        /* Visualizations */
        .viz-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(400px, 1fr));
            gap: 25px;
            margin-bottom: 40px;
        }
        
        .viz-panel {
            background: var(--panel-bg);
            border-radius: 20px;
            padding: 25px;
            border: 2px solid var(--border);
            backdrop-filter: blur(15px);
            transition: all 0.3s ease;
        }
        
        .viz-panel:hover {
            border-color: var(--primary);
            box-shadow: 0 15px 40px rgba(0, 255, 136, 0.2);
        }
        
        .viz-title {
            font-family: 'Orbitron', monospace;
            font-size: 1.1em;
            font-weight: 700;
            color: var(--primary);
            margin-bottom: 20px;
            display: flex;
            align-items: center;
            justify-content: space-between;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .viz-canvas {
            display: block;
            width: 100%;
            height: 300px;
            background: #0a0a0a;
            border: 1px solid rgba(0, 255, 136, 0.3);
            width: 100%;
            height: 300px;
            border-radius: 15px;
            background: rgba(0, 0, 0, 0.4);
            border: 1px solid var(--border);
            margin-bottom: 15px;
        }
        
        .controls-section {
            display: flex;
            gap: 10px;
            justify-content: center;
        }
        
        .control-btn {
            padding: 8px 15px;
            background: rgba(255, 255, 255, 0.1);
            border: 1px solid var(--border);
            border-radius: 20px;
            color: var(--text-secondary);
            font-size: 0.8em;
            cursor: pointer;
            transition: all 0.3s ease;
            font-family: 'JetBrains Mono', monospace;
        }
        
        .control-btn:hover,
        .control-btn.active {
            background: var(--primary);
            color: var(--bg-dark);
            border-color: var(--primary);
        }
        
        /* Power-ups */
        .powerups-section {
            background: var(--panel-bg);
            border-radius: 20px;
            padding: 30px;
            border: 2px solid var(--warning);
            margin-bottom: 40px;
        }
        
        .powerups-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-bottom: 30px;
        }
        
        .powerup-card {
            background: linear-gradient(135deg, rgba(255, 255, 255, 0.05), rgba(255, 255, 255, 0.02));
            border: 2px solid var(--border);
            border-radius: 15px;
            padding: 25px;
            text-align: center;
            cursor: pointer;
            transition: all 0.4s ease;
            position: relative;
            overflow: hidden;
        }
        
        .powerup-card:hover {
            border-color: var(--warning);
            background: linear-gradient(135deg, rgba(255, 165, 0, 0.1), rgba(255, 165, 0, 0.05));
            transform: translateY(-5px);
            box-shadow: 0 20px 40px rgba(255, 165, 0, 0.3);
        }
        
        .powerup-card.active {
            border-color: var(--warning);
            background: linear-gradient(135deg, rgba(255, 165, 0, 0.2), rgba(255, 165, 0, 0.1));
        }
        
        .powerup-icon {
            font-size: 2.5em;
            margin-bottom: 15px;
        }
        
        .powerup-title {
            font-family: 'Orbitron', monospace;
            font-size: 1em;
            font-weight: 700;
            color: var(--warning);
            margin-bottom: 10px;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .powerup-desc {
            font-size: 0.85em;
            color: var(--text-secondary);
            line-height: 1.4;
        }
        
        .powerup-results {
            background: rgba(0, 0, 0, 0.3);
            border-radius: 15px;
            padding: 20px;
            border: 1px solid var(--border);
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.9em;
            color: var(--text-secondary);
            text-align: center;
            min-height: 100px;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        /* Analysis Sections */
        .analysis-sections {
            display: grid;
            gap: 30px;
        }
        
        .analysis-section {
            background: var(--panel-bg);
            border-radius: 20px;
            padding: 0;
            border: 2px solid var(--border);
            backdrop-filter: blur(15px);
            overflow: hidden;
        }
        
        .analysis-section.psychological { border-color: var(--psych-color); }
        .analysis-section.narrative { border-color: var(--narrative-color); }
        .analysis-section.technical { border-color: var(--technical-color); }
        .analysis-section.cultural { border-color: var(--cultural-color); }
        .analysis-section.gaming { border-color: var(--gaming-color); }
        
        .section-header {
            padding: 25px 30px;
            cursor: pointer;
            display: flex;
            align-items: center;
            justify-content: space-between;
            background: rgba(255, 255, 255, 0.02);
            transition: all 0.3s ease;
        }
        
        .section-header:hover {
            background: rgba(255, 255, 255, 0.05);
        }
        
        .section-title {
            display: flex;
            align-items: center;
            gap: 15px;
            font-family: 'Orbitron', monospace;
            font-size: 1.3em;
            font-weight: 700;
            text-transform: uppercase;
            letter-spacing: 1px;
        }
        
        .section-icon {
            font-size: 1.5em;
        }
        
        .expand-btn {
            width: 35px;
            height: 35px;
            border-radius: 50%;
            background: var(--primary);
            color: var(--bg-dark);
            border: none;
            cursor: pointer;
            font-weight: bold;
            font-size: 1.2em;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .expand-btn:hover {
            transform: scale(1.1);
            box-shadow: 0 0 20px var(--primary);
        }
        
        .expand-btn.expanded {
            transform: rotate(180deg);
        }
        
        .section-content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.5s ease;
        }
        
        .section-content.expanded {
            max-height: 2000px;
        }
        
        .content-inner {
            padding: 30px;
        }
        
        .analysis-cards {
            display: grid;
            gap: 20px;
        }
        
        .analysis-card {
            background: linear-gradient(135deg, rgba(255, 255, 255, 0.08), rgba(255, 255, 255, 0.03));
            border: 1px solid var(--border);
            border-radius: 15px;
            padding: 25px;
            transition: all 0.3s ease;
        }
        
        .analysis-card:hover {
            background: linear-gradient(135deg, rgba(255, 255, 255, 0.12), rgba(255, 255, 255, 0.06));
            border-color: var(--primary);
            transform: translateY(-3px);
        }
        
        .card-header {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 15px;
        }
        
        .card-title {
            font-family: 'JetBrains Mono', monospace;
            font-weight: 700;
            font-size: 1.1em;
            color: var(--text-primary);
        }
        
        .card-score {
            font-family: 'Orbitron', monospace;
            font-weight: 700;
            font-size: 1em;
            padding: 8px 15px;
            border-radius: 25px;
            text-align: center;
            min-width: 80px;
        }
        
        .card-score.high {
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: var(--bg-dark);
        }
        
        .card-score.medium {
            background: linear-gradient(135deg, var(--warning), #ffb84d);
            color: var(--bg-dark);
        }
        
        .card-score.low {
            background: linear-gradient(135deg, var(--accent), #ff8a8a);
            color: var(--text-primary);
        }
        
        .card-description {
            color: var(--text-secondary);
            line-height: 1.6;
            font-size: 0.95em;
        }
        
        /* AI Conversation */
        .conversation-panel {
            background: var(--panel-bg);
            border-radius: 20px;
            padding: 25px;
            border: 2px solid var(--info);
            height: 500px;
            display: flex;
            flex-direction: column;
        }

        /* Inline API key UI (Bytez) */
        .api-key-box {
            margin: 10px 0 15px;
            padding: 12px;
            border-radius: 12px;
            border: 1px solid rgba(255, 255, 255, 0.12);
            background: rgba(0, 0, 0, 0.25);
        }

        .api-key-title {
            display: flex;
            justify-content: space-between;
            align-items: center;
            gap: 10px;
            margin-bottom: 10px;
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.85em;
            color: var(--text-secondary);
        }

        .api-key-status {
            color: var(--text-secondary);
            font-size: 0.85em;
            white-space: nowrap;
        }

        .api-key-row {
            display: flex;
            gap: 10px;
            align-items: center;
        }

        .api-key-row.stack {
            flex-direction: column;
            align-items: stretch;
        }

        .api-key-row.stack > .api-key-row {
            margin-top: 10px;
        }

        .api-key-select {
            width: 100%;
            padding: 10px 14px;
            border: 2px solid var(--border);
            border-radius: 12px;
            background: rgba(0, 0, 0, 0.35);
            color: var(--text-primary);
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.85em;
        }

        .api-key-input {
            flex: 1;
            padding: 10px 14px;
            border: 2px solid var(--border);
            border-radius: 12px;
            background: rgba(0, 0, 0, 0.35);
            color: var(--text-primary);
            font-family: 'JetBrains Mono', monospace;
            font-size: 0.85em;
        }

        .api-key-btn {
            padding: 10px 14px;
            border-radius: 12px;
            border: 1px solid rgba(255, 255, 255, 0.12);
            background: rgba(0, 255, 136, 0.12);
            color: var(--primary);
            font-family: 'JetBrains Mono', monospace;
            font-weight: 700;
            cursor: pointer;
            transition: all 0.2s ease;
        }

        .api-key-btn:hover {
            background: rgba(0, 255, 136, 0.18);
            border-color: rgba(0, 255, 136, 0.35);
        }

        .api-key-btn.secondary {
            background: rgba(255, 107, 107, 0.10);
            color: var(--accent);
        }

        .api-key-btn.secondary:hover {
            background: rgba(255, 107, 107, 0.16);
            border-color: rgba(255, 107, 107, 0.35);
        }

        .api-key-help {
            margin-top: 8px;
            color: var(--text-secondary);
            font-size: 0.8em;
            line-height: 1.4;
        }

        
        .conversation-history {
            flex: 1;
            overflow-y: auto;
            margin-bottom: 20px;
            padding: 15px;
            background: rgba(0, 0, 0, 0.3);
            border-radius: 15px;
            border: 1px solid var(--border);
        }
        
        .message {
            margin-bottom: 15px;
            padding: 12px 18px;
            border-radius: 15px;
            max-width: 85%;
            font-size: 0.9em;
            line-height: 1.5;
        }
        
        .message.ai {
            background: linear-gradient(135deg, var(--info), var(--purple));
            color: var(--bg-dark);
            margin-right: auto;
            border-bottom-left-radius: 5px;
        }
        
        .message.user {
            background: linear-gradient(135deg, var(--primary), var(--secondary));
            color: var(--bg-dark);
            margin-left: auto;
            border-bottom-right-radius: 5px;
        }
        
        .conversation-input {
            display: flex;
            gap: 10px;
        }
        
        .chat-input {
            flex: 1;
            padding: 12px 18px;
            border: 2px solid var(--border);
            border-radius: 25px;
            background: rgba(0, 0, 0, 0.4);
            color: var(--text-primary);
            font-family: inherit;
            font-size: 0.9em;
        }
        
        .chat-input:focus {
            outline: none;
            border-color: var(--info);
            box-shadow: 0 0 15px rgba(100, 216, 255, 0.3);
        }
        
        .send-btn {
            padding: 12px 20px;
            background: linear-gradient(135deg, var(--info), var(--purple));
            color: var(--bg-dark);
            border: none;
            border-radius: 25px;
            cursor: pointer;
            font-weight: 600;
            transition: all 0.3s ease;
        }
        
        .send-btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 25px rgba(100, 216, 255, 0.4);
        }
        
        /* Hide file input */
        input[type="file"] {
            display: none;
        }
        
        /* Responsive Design */
        @media (max-width: 1200px) {
            .main-layout {
                grid-template-columns: 1fr;
            }
            
            .viz-grid {
                grid-template-columns: 1fr;
            }
            
            .powerups-grid {
                grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            }
        }
        
        @media (max-width: 768px) {
            .header h1 {
                font-size: 2.5em;
            }
            
            .viz-grid {
                grid-template-columns: 1fr;
            }
            
            .powerups-grid {
                grid-template-columns: 1fr;
            }
            
            .scores-grid {
                grid-template-columns: 1fr;
            }
        }
        
        /* Scrollbar Styling */
        ::-webkit-scrollbar {
            width: 8px;
        }
        
        ::-webkit-scrollbar-track {
            background: var(--bg-dark);
        }
        
        ::-webkit-scrollbar-thumb {
            background: var(--primary);
            border-radius: 4px;
        }
        
        ::-webkit-scrollbar-thumb:hover {
            background: var(--info);
        }
        
        /* Loading and Error States */
        .loading {
            display: inline-block;
            width: 20px;
            height: 20px;
            border: 2px solid var(--border);
            border-radius: 50%;
            border-top-color: var(--primary);
            animation: spin 1s ease-in-out infinite;
        }
        
        @keyframes spin {
            to { transform: rotate(360deg); }
        }
        
        .error {
            position: fixed;
            top: 20px;
            right: 20px;
            background: var(--accent);
            color: white;
            padding: 15px 20px;
            border-radius: 10px;
            font-weight: 600;
            z-index: 1000;
            animation: slideIn 0.3s ease;
        }
        
        .success {
            position: fixed;
            top: 20px;
            right: 20px;
            background: var(--primary);
            color: var(--bg-dark);
            padding: 15px 20px;
            border-radius: 10px;
            font-weight: 600;
            z-index: 1000;
            animation: slideIn 0.3s ease;
        }
        
        @keyframes slideIn {
            from { transform: translateX(100%); opacity: 0; }
            to { transform: translateX(0); opacity: 1; }
        }
    </style>
    <!-- Bytez API is called via HTTP fetch() (no SDK required) -->
</head>
<body>
    <div class="container">
        <!-- Header -->
        <div class="header">
            <div class="header-content">
                <h1>AUDIO FORENSICS PRO</h1>
                <div class="subtitle">Complete Neural Analysis Matrix</div>
                <div class="subtitle">Advanced AI-Powered Audio Investigation Suite</div>
            </div>
        </div>

        <!-- Upload Zone -->
        <div class="upload-zone" id="uploadZone">
            <h3 style="margin-bottom: 20px; font-family: 'Orbitron', monospace;">DRAG AUDIO FILE OR CLICK TO UPLOAD</h3>
            <button class="upload-btn" id="uploadBtn" type="button" onclick="document.getElementById('fileInput')?.click();">
                SELECT AUDIO FILE
            </button>
            <input type="file" id="fileInput" accept="audio/*" style="display: none;" onchange="handleFileSelect(event)">
            <p style="margin-top: 20px; color: var(--text-secondary);">
                Supports: MP3, WAV, FLAC, OGG, M4A, AAC, AIFF
            </p>

            <!-- Optional: let users paste their own Bytez API key before upload -->
            <div class="api-key-box" style="max-width: 720px; margin: 22px auto 0;">
                <div class="api-key-title">
                    <span>Optional: AI Provider (enables AI)</span>
                    <span class="api-key-status" id="bytezKeyStatusUpload">AI: disabled</span>
                </div>
                <div class="api-key-row stack">
                    <div>
                        <select class="api-key-select" id="aiProviderSelectUpload">
                            <option value="bytez">AI provider: Bytez</option>
                            <option value="custom">AI provider: Custom endpoint</option>
                        </select>
                    </div>
                    <div>
                        <select class="api-key-select" id="aiAudioSendModeUpload">
                            <option value="10">AI audio window: 10s clip</option>
                            <option value="15">AI audio window: 15s clip</option>
                            <option value="20">AI audio window: 20s clip</option>
                            <option value="30">AI audio window: 30s clip</option>
                            <option value="45">AI audio window: 45s clip</option>
                            <option value="60">AI audio window: 60s clip</option>
                            <option value="full">AI audio window: entire file (may fail if too large)</option>
                        </select>
                    </div>
                    <div id="customAiBoxUpload" style="display:none;">
                        <input class="api-key-input" id="customAiChatUrlUpload" type="text" autocomplete="off" placeholder="Custom chat endpoint URL (Bytez-compatible proxy)">
                        <div style="height:8px"></div>
                        <input class="api-key-input" id="customAiAuthHeaderValueUpload" type="password" autocomplete="off" placeholder="Custom auth header value (optional)">
                        <div style="margin-top:8px; color: var(--text-secondary); font-size: 0.78em; line-height: 1.4;">
                            For non-Bytez AIs in a static site, use a proxy endpoint you control (must allow CORS). Expected response: <code>{ error, output }</code>.
                        </div>
                    </div>
                    <div class="api-key-row" id="bytezAiBoxUpload">
                        <input class="api-key-input" id="bytezKeyInputUpload" type="password" autocomplete="off" placeholder="Paste your Bytez key here (stored in this browser)">
                        <button class="api-key-btn" id="bytezKeySaveUpload" type="button" onclick="setBytezApiKey(document.getElementById('bytezKeyInputUpload')?.value || '')">Save</button>
                        <button class="api-key-btn secondary" id="bytezKeyTestUpload" type="button" onclick="testBytezKey(document.getElementById('bytezKeyInputUpload')?.value || '')">Test</button>
                        <button class="api-key-btn secondary" id="bytezKeyClearUpload" type="button" onclick="clearBytezApiKey()">Clear</button>
                    </div>
                </div>
                <div class="api-key-help">
                    This is a static site: the key is saved to <code>localStorage</code> on this device only. Get a key at <code>https://bytez.com/api/key</code>. Tip: click <strong>Test</strong> to verify your key before GO.
                </div>
            </div>
            
            <!-- GO Button -->
            <div style="margin-top: 40px; padding: 30px; background: rgba(0, 255, 136, 0.1); border: 2px solid var(--success); border-radius: 20px; text-align: center;">
                <h3 style="margin-bottom: 20px; font-family: 'Orbitron', monospace; color: var(--success);">READY TO ANALYZE?</h3>
                <div id="fileStatus" style="margin-bottom: 20px; color: var(--text-secondary); font-size: 1em; font-weight: 600;">
                    No file selected
                </div>
                <button class="upload-btn" id="goBtn" type="button" onclick="startAnalysis()" disabled style="opacity: 0.5; cursor: not-allowed; font-size: 1.5em; padding: 25px 80px;">
                    GO!
                </button>
                <p style="margin-top: 20px; color: var(--text-secondary); font-size: 0.9em;">
                    üëÜ Select a file above, configure AI (optional), then click GO to start analysis
                </p>
            </div>
        </div>

        <!-- Main Layout -->
        <div class="main-layout" id="mainLayout">
            <!-- Primary Content -->
            <div class="primary-content">
                <!-- Audio Player and Metadata -->
                <div class="player-section">
                    <div class="panel-header">
                        <h3 class="panel-title" style="color: var(--technical-color);">üéµ Audio Player</h3>
                        <button class="help-btn" onclick="toggleTooltip('player-help')">?</button>
                        <div class="tooltip" id="player-help">
                            Control playback and view file metadata. Analysis begins when you start playing the track.
                        </div>
                    </div>
                    
                    <div class="audio-controls">
                        <audio id="audioPlayer" controls></audio>
                        <div class="metadata-grid" id="metadata">
                            <!-- Populated by JavaScript -->
                        </div>
                    </div>
                    
                    <div class="scores-grid">
                        <div class="score-card flow">
                            <div class="score-number" id="flowScore">--</div>
                            <div class="score-label">Flow State</div>
                        </div>
                        <div class="score-card tension">
                            <div class="score-number" id="tensionScore">--</div>
                            <div class="score-label">Tension</div>
                        </div>
                        <div class="score-card complexity">
                            <div class="score-number" id="complexityScore">--</div>
                            <div class="score-label">Complexity</div>
                        </div>
                    </div>
                </div>

                <!-- Advanced Visualizations -->
                <div class="viz-grid">
                    <div class="viz-panel">
                        <div class="viz-title">
                            3D Frequency Waterfall
                            <button class="help-btn" onclick="toggleTooltip('waterfall-help')">?</button>
                            <div class="tooltip" id="waterfall-help">
                                Real-time 3D spectrogram that builds up layers as your track plays - like a waterfall of frequencies flowing over time.
                            </div>
                        </div>
                        <canvas class="viz-canvas" id="waterfallCanvas"></canvas>
                        <div class="controls-section">
                            <button class="control-btn active" onclick="setWaterfallMode('3d')">3D View</button>
                            <button class="control-btn" onclick="setWaterfallMode('flat')">Flat View</button>
                            <button class="control-btn" onclick="setWaterfallMode('rotating')">Rotate</button>
                        </div>
                    </div>
                    
                    <div class="viz-panel">
                        <div class="viz-title">
                            Neural Network Visualization
                            <button class="help-btn" onclick="toggleTooltip('neural-help')">?</button>
                            <div class="tooltip" id="neural-help">
                                Watch how an AI "brain" processes your music - nodes light up and connect based on different audio features.
                            </div>
                        </div>
                        <canvas class="viz-canvas" id="neuralCanvas"></canvas>
                        <div class="controls-section">
                            <button class="control-btn active" onclick="setNeuralMode('frequency')">Frequency</button>
                            <button class="control-btn" onclick="setNeuralMode('emotion')">Emotion</button>
                            <button class="control-btn" onclick="setNeuralMode('complexity')">Complexity</button>
                        </div>
                    </div>
                    
                    <div class="viz-panel">
                        <div class="viz-title">
                            Particle Audio Reactive
                            <button class="help-btn" onclick="toggleTooltip('particle-help')">?</button>
                            <div class="tooltip" id="particle-help">
                                Thousands of particles that dance to your music - different frequency bands control color, size, and movement patterns.
                            </div>
                        </div>
                        <canvas class="viz-canvas" id="particleCanvas"></canvas>
                        <div class="controls-section">
                            <button class="control-btn active" onclick="setParticleMode('frequency')">Frequency</button>
                            <button class="control-btn" onclick="setParticleMode('energy')">Energy</button>
                            <button class="control-btn" onclick="setParticleMode('chaos')">Chaos</button>
                        </div>
                    </div>
                    
                    <div class="viz-panel">
                        <div class="viz-title">
                            Stereo Field Analysis
                            <button class="help-btn" onclick="toggleTooltip('stereo-help')">?</button>
                            <div class="tooltip" id="stereo-help">
                                Real-time map of where sounds are positioned in the stereo field - see instruments move left, right, and center.
                            </div>
                        </div>
                        <canvas class="viz-canvas" id="stereoCanvas"></canvas>
                        <div class="controls-section">
                            <button class="control-btn active" onclick="setStereoMode('live')">Live</button>
                            <button class="control-btn" onclick="setStereoMode('history')">History</button>
                            <button class="control-btn" onclick="setStereoMode('correlation')">Correlation</button>
                        </div>
                    </div>
                </div>
                
                <!-- Technical Power-Ups Section -->
                <div class="powerups-section">
                    <div class="panel-header">
                        <h3 class="panel-title" style="color: var(--warning);">‚ö° Technical Power-Ups</h3>
                        <button class="help-btn" onclick="toggleTooltip('powerups-help')">?</button>
                        <div class="tooltip" id="powerups-help">
                            Advanced AI-powered tools for deep audio analysis - MIDI generation, source separation, beat detection, and more.
                        </div>
                    </div>
                    
                    <div class="powerups-grid">
                        <div class="powerup-card" onclick="generateMIDI(event)">
                            <div class="powerup-icon">üéπ</div>
                            <div class="powerup-title">MIDI Generation</div>
                            <div class="powerup-desc">AI recreates musical elements as MIDI data</div>
                        </div>
                        
                        <div class="powerup-card" onclick="isolateElements(event)">
                            <div class="powerup-icon">üéöÔ∏è</div>
                            <div class="powerup-title">Source Separation</div>
                            <div class="powerup-desc">Isolate vocals, drums, bass, and instruments</div>
                        </div>
                        
                        <div class="powerup-card" onclick="detectBeatTempo(event)">
                            <div class="powerup-icon">ü•Å</div>
                            <div class="powerup-title">Beat/Tempo Detection</div>
                            <div class="powerup-desc">Advanced rhythmic analysis and BPM detection</div>
                        </div>
                        
                        <div class="powerup-card" onclick="detectKeyChords(event)">
                            <div class="powerup-icon">üéº</div>
                            <div class="powerup-title">Key/Chord Analysis</div>
                            <div class="powerup-desc">Musical theory analysis and chord progression</div>
                        </div>
                        
                        <div class="powerup-card" onclick="analyzeGenre(event)">
                            <div class="powerup-icon">üéµ</div>
                            <div class="powerup-title">Style / Genre Analysis</div>
                            <div class="powerup-desc">Multi-genre suggestions and reference points (no forced lane)</div>
                        </div>
                    </div>
                    
                    <div class="powerup-results" id="powerupResults">
                        Click any power-up above to perform advanced analysis...
                    </div>
                </div>
                
                <!-- Comprehensive Analysis Sections -->
                <div class="analysis-sections">
                    
                    <!-- Psychological Analysis -->
                    <div class="analysis-section psychological">
                        <div class="section-header" onclick="toggleSection('psychological')">
                            <div class="section-title">
                                <div class="section-icon">üß†</div>
                                <span>Psychological Analysis</span>
                            </div>
                            <div class="expand-btn">‚ñº</div>
                        </div>
                        <div class="section-content" id="psychological-content">
                            <div class="content-inner">
                                <div class="analysis-cards" id="psychological-cards">
                                    <div style="text-align: center; color: var(--text-secondary); font-style: italic; padding: 20px;">
                                        Upload an audio file to begin analysis...
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Narrative Analysis -->
                    <div class="analysis-section narrative">
                        <div class="section-header" onclick="toggleSection('narrative')">
                            <div class="section-title">
                                <div class="section-icon">üìñ</div>
                                <span>Narrative Analysis</span>
                            </div>
                            <div class="expand-btn">‚ñº</div>
                        </div>
                        <div class="section-content" id="narrative-content">
                            <div class="content-inner">
                                <div class="analysis-cards" id="narrative-cards">
                                    <div style="text-align: center; color: var(--text-secondary); font-style: italic; padding: 20px;">
                                        Upload an audio file to begin analysis...
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Technical Analysis -->
                    <div class="analysis-section technical">
                        <div class="section-header" onclick="toggleSection('technical')">
                            <div class="section-title">
                                <div class="section-icon">‚öôÔ∏è</div>
                                <span>Technical Forensics</span>
                            </div>
                            <div class="expand-btn">‚ñº</div>
                        </div>
                        <div class="section-content" id="technical-content">
                            <div class="content-inner">
                                <div class="analysis-cards" id="technical-cards">
                                    <div style="text-align: center; color: var(--text-secondary); font-style: italic; padding: 20px;">
                                        Upload an audio file to begin analysis...
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Cultural Analysis -->
                    <div class="analysis-section cultural">
                        <div class="section-header" onclick="toggleSection('cultural')">
                            <div class="section-title">
                                <div class="section-icon">üåê</div>
                                <span>Cultural Context</span>
                            </div>
                            <div class="expand-btn">‚ñº</div>
                        </div>
                        <div class="section-content" id="cultural-content">
                            <div class="content-inner">
                                <div class="analysis-cards" id="cultural-cards">
                                    <div style="text-align: center; color: var(--text-secondary); font-style: italic; padding: 20px;">
                                        Upload an audio file to begin analysis...
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Gaming Analysis -->
                    <div class="analysis-section gaming">
                        <div class="section-header" onclick="toggleSection('gaming')">
                            <div class="section-title">
                                <div class="section-icon">üéÆ</div>
                                <span>Gaming Integration</span>
                            </div>
                            <div class="expand-btn">‚ñº</div>
                        </div>
                        <div class="section-content" id="gaming-content">
                            <div class="content-inner">
                                <div class="analysis-cards" id="gaming-cards">
                                    <div style="text-align: center; color: var(--text-secondary); font-style: italic; padding: 20px;">
                                        Upload an audio file to begin analysis...
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                    
                    <!-- Genre Analysis -->
                    <div class="analysis-section" style="border-color: var(--purple);">
                        <div class="section-header" onclick="toggleSection('genre')">
                            <div class="section-title" style="color: var(--purple);">
                                <div class="section-icon">üéµ</div>
                                <span>Genre Classification & Recommendations</span>
                            </div>
                            <div class="expand-btn">‚ñº</div>
                        </div>
                        <div class="section-content" id="genre-content">
                            <div class="content-inner">
                                <div class="analysis-cards" id="genre-cards">
                                    <div style="text-align: center; color: var(--text-secondary); font-style: italic; padding: 20px;">
                                        Upload an audio file to begin analysis...
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
            
            <!-- Sidebar -->
                <div class="sidebar">
                    <!-- AI Conversation -->
                    <div class="conversation-panel">
                        <div class="panel-header">
                            <h3 class="panel-title" style="color: var(--info);">üí¨ AI Chat</h3>
                            <button class="help-btn" onclick="toggleTooltip('ai-help')">?</button>
                            <div class="tooltip" id="ai-help">
                                Ask questions about the uploaded track. AI analyzes the uploaded audio file (not your microphone / live system audio).
                            </div>
                        </div>

                        <!-- API Key Box - positioned above chat -->
                        <div class="api-key-box" id="bytezKeyBoxChat" style="margin-bottom: 15px;">
                            <div class="api-key-title">
                                <span>AI Provider</span>
                                <span class="api-key-status" id="bytezKeyStatusChat">AI: disabled</span>
                            </div>
                            <div class="api-key-row stack">
                                <div>
                                    <select class="api-key-select" id="aiProviderSelectChat">
                                        <option value="bytez">AI provider: Bytez</option>
                                        <option value="custom">AI provider: Custom endpoint</option>
                                    </select>
                                </div>
                                <div>
                                    <select class="api-key-select" id="aiAudioSendModeChat">
                                        <option value="10">AI audio window: 10s clip</option>
                                        <option value="15">AI audio window: 15s clip</option>
                                        <option value="20">AI audio window: 20s clip</option>
                                        <option value="30">AI audio window: 30s clip</option>
                                        <option value="45">AI audio window: 45s clip</option>
                                        <option value="60">AI audio window: 60s clip</option>
                                        <option value="full">AI audio window: entire file (may fail if too large)</option>
                                    </select>
                                </div>
                                <div id="customAiBoxChat" style="display:none;">
                                    <input class="api-key-input" id="customAiChatUrlChat" type="text" autocomplete="off" placeholder="Custom chat endpoint URL (Bytez-compatible proxy)">
                                    <div style="height:8px"></div>
                                    <input class="api-key-input" id="customAiAuthHeaderValueChat" type="password" autocomplete="off" placeholder="Custom auth header value (optional)">
                                    <div style="margin-top:8px; color: var(--text-secondary); font-size: 0.78em; line-height: 1.4;">
                                        For non-Bytez AIs in a static site, use a proxy endpoint you control (must allow CORS). Expected response: <code>{ error, output }</code>.
                                    </div>
                                </div>
                                <div class="api-key-row" id="bytezAiBoxChat">
                                    <input class="api-key-input" id="bytezKeyInputChat" type="password" autocomplete="off" placeholder="Paste your Bytez key to enable AI chat + analysis">
                                    <button class="api-key-btn" id="bytezKeySaveChat" type="button">Save</button>
                                    <button class="api-key-btn secondary" id="bytezKeyTestChat" type="button" onclick="testBytezKey(document.getElementById('bytezKeyInputChat')?.value || '')">Test</button>
                                    <button class="api-key-btn secondary" id="bytezKeyClearChat" type="button">Clear</button>
                                </div>
                            </div>
                            <div class="api-key-help">
                                Stored locally in this browser only. Tip: click <strong>Test</strong> to verify your key. You can also use the ‚öôÔ∏è button in the AI Analysis panel.
                            </div>
                        </div>

                        <div class="conversation-history" id="conversationHistory">
                        <div class="message ai">
                            <div class="message-content">
                                üëã Hello! Upload an audio file and I'll help you analyze it. You can ask me anything about the music, from technical details to creative insights. I remember our conversation, so feel free to ask follow-up questions!
                            </div>
                        </div>
                    </div>
                    
                    <div class="conversation-input">
                        <input type="text" class="chat-input" id="chatInput" placeholder="Ask me about your track..." onkeypress="if(event.key==='Enter') sendMessage()">
                        <button class="send-btn" onclick="sendMessage()">Send</button>
                    </div>
                </div>
                
                <!-- Genre Recommendations -->
                <div class="panel">
                    <div class="panel-header">
                        <h3 class="panel-title" style="color: var(--purple);">üéµ Style / Genre</h3>
                        <button class="help-btn" onclick="toggleTooltip('genre-help')">?</button>
                        <div class="tooltip" id="genre-help">
                            Style/genre suggestions and discovery anchors. Genre is fuzzy ‚Äî this tool avoids forcing a single label.
                        </div>
                    </div>
                    

                    <div id="genre-cards">
                        <div style="text-align: center; color: var(--text-secondary); font-style: italic;">
                            Upload audio to analyze style/genre characteristics...
                        </div>
                    </div>
                </div>
                
            </div>
        </div>
    </div>

    <script>
        // Global variables
        let audioContext;
        let audioElement;
        let mediaSource;
        let analyserNode;
        let leftAnalyser;
        let rightAnalyser;
        let splitterNode;
        let isolationInputGain;
        let isolationDryGain;
        let isolationWetGain;
        let isolationMix = 1.0; // 0=dry(full) 1=wet(isolated)
        let isolationFilters = [];
        let isolationMode = 'full'; // full|vocals|drums|bass|instruments
        let isPlaying = false;
        let animationFrames = {};
        let conversationHistory = [];
        let hasFilledAISectionsOnce = false;
        
        // Visualization modes
        let waterfallMode = '3d';
        let neuralMode = 'frequency';
        let particleMode = 'frequency';
        let stereoMode = 'live';
        
        // Real-time analysis data
        let frequencyData;
        let timeData;
        let leftFreqData;
        let rightFreqData;
        let particles = [];
        let neuralNodes = [];
        let neuralConnections = [];
        
        // Canvas contexts
        let waterfallCtx;
        let neuralCtx;
        let particleCtx;
        let stereoCtx;
        
        // Audio analysis variables
        let currentFreqAvg = 0;
        let currentBass = 0;
        let currentMid = 0;
        let currentHigh = 0;
        let currentVolume = 0;
        
        // Initialize
        document.addEventListener('DOMContentLoaded', function() {
            // Ensure main layout is hidden on page load
            const mainLayout = document.getElementById('mainLayout');
            if (mainLayout) {
                mainLayout.style.display = 'none';
                mainLayout.classList.remove('active');
                console.log('Main layout hidden on page load');
            }
            
            initializeAudio();
            setupEventListeners();
            initializeCanvases();
            setupNeuralNetwork();
            initializeParticles();
            
            // Initialize AI provider (Bytez or custom)
            initializeAIProvider();

            // Reflect key state in the UI (front page + chat)
            updateApiKeyUi();
            syncAiAudioWindowUi();
            
            // Initialize GO button state
            updateGoButtonState();
            
            // Verify GO button exists
            const goBtn = document.getElementById('goBtn');
            if (goBtn) {
                console.log('‚úì GO button found and initialized');
            } else {
                console.error('‚úó GO button NOT FOUND! Check HTML structure.');
                // Try to create it if missing
                const uploadZone = document.getElementById('uploadZone');
                if (uploadZone) {
                    const goDiv = document.createElement('div');
                    goDiv.innerHTML = `
                        <div style="margin-top: 40px; padding: 30px; background: rgba(0, 255, 136, 0.1); border: 2px solid var(--success); border-radius: 20px; text-align: center;">
                            <h3 style="margin-bottom: 20px; font-family: 'Orbitron', monospace; color: var(--success);">READY TO ANALYZE?</h3>
                            <div id="fileStatus" style="margin-bottom: 20px; color: var(--text-secondary); font-size: 1em; font-weight: 600;">No file selected</div>
                            <button class="upload-btn" id="goBtn" type="button" onclick="startAnalysis()" disabled style="opacity: 0.5; cursor: not-allowed; font-size: 1.5em; padding: 25px 80px;">GO!</button>
                            <p style="margin-top: 20px; color: var(--text-secondary); font-size: 0.9em;">üëÜ Select a file above, configure AI (optional), then click GO to start analysis</p>
                        </div>
                    `;
                    uploadZone.appendChild(goDiv);
                    console.log('‚úì GO button created dynamically');
                }
            }
            
            // Start visualization loops (safe to call repeatedly)
            startVisualizationLoops();
        });

        // Basic runtime guardrails: surface unexpected errors in the UI
        window.addEventListener('error', (e) => {
            try {
                console.error('Runtime error:', e?.error || e);
                showError(`Runtime error: ${(e?.error?.message || e?.message || 'unknown')}`);
            } catch {}
        });
        window.addEventListener('unhandledrejection', (e) => {
            try {
                console.error('Unhandled rejection:', e?.reason || e);
                showError(`Unhandled promise: ${(e?.reason?.message || String(e?.reason || 'unknown'))}`);
            } catch {}
        });
        
        function startVisualizationLoops(attempt = 0) {
            // Ensure canvases exist/are sized
            if (!waterfallCtx || !neuralCtx || !particleCtx || !stereoCtx) {
                initializeCanvases();
            }
            
            // If still not ready, retry a few times (e.g. first paint/layout)
            if ((!waterfallCtx || !neuralCtx || !particleCtx || !stereoCtx) && attempt < 25) {
                setTimeout(() => startVisualizationLoops(attempt + 1), 100);
                return;
            }
            
            // Start animation loops only once each
            if (!animationFrames || typeof animationFrames !== 'object') {
                animationFrames = {};
            }
            if (!animationFrames.waterfall) animateWaterfall();
            if (!animationFrames.neural) animateNeuralNetwork();
            if (!animationFrames.particles) animateParticles();
            if (!animationFrames.stereo) animateStereoField();
        }
        
        function initializeAudio() {
            try {
                // Create audio context with proper error handling
                window.AudioContext = window.AudioContext || window.webkitAudioContext;
                if (!window.AudioContext) {
                    throw new Error('Web Audio API not supported');
                }
                audioContext = new AudioContext();
                console.log('Audio context initialized:', audioContext.state);
            } catch (e) {
                console.error('Web Audio API not supported:', e);
                showError('Web Audio API not supported in this browser');
            }
        }
        
        function initializeCanvases() {
            try {
                const waterfallCanvas = document.getElementById('waterfallCanvas');
                const neuralCanvas = document.getElementById('neuralCanvas');
                const particleCanvas = document.getElementById('particleCanvas');
                const stereoCanvas = document.getElementById('stereoCanvas');
                
                if (!waterfallCanvas || !neuralCanvas || !particleCanvas || !stereoCanvas) {
                    console.error('Canvas elements not found! Make sure mainLayout is visible.');
                    return;
                }
                
                waterfallCtx = waterfallCanvas.getContext('2d');
                neuralCtx = neuralCanvas.getContext('2d');
                particleCtx = particleCanvas.getContext('2d');
                stereoCtx = stereoCanvas.getContext('2d');
                
                if (!waterfallCtx || !neuralCtx || !particleCtx || !stereoCtx) {
                    console.error('Failed to get canvas contexts!');
                    return;
                }
                
                console.log('Canvas contexts initialized successfully');
                
                // Set canvas sizes
                resizeCanvases();
                
                // Initialize with visible content so user knows canvases are working
                initializeCanvasBackgrounds();
                
            } catch (error) {
                console.error('Error initializing canvases:', error);
            }
        }
        
        function initializeCanvasBackgrounds() {
            // Draw initial content on all canvases so they're not just black
            const canvases = [
                { ctx: waterfallCtx, name: 'Waterfall' },
                { ctx: neuralCtx, name: 'Neural Network' },
                { ctx: particleCtx, name: 'Particles' },
                { ctx: stereoCtx, name: 'Stereo Field' }
            ];
            
            canvases.forEach(({ ctx, name }) => {
                if (!ctx) return;
                
                const canvas = ctx.canvas;
                const width = canvas.width / window.devicePixelRatio;
                const height = canvas.height / window.devicePixelRatio;
                
                // Clear with dark background
                ctx.fillStyle = '#0a0a0a';
                ctx.fillRect(0, 0, width, height);
                
                // Draw title text
                ctx.fillStyle = '#00ff88';
                ctx.font = 'bold 16px Orbitron, monospace';
                ctx.textAlign = 'center';
                ctx.textBaseline = 'middle';
                ctx.fillText(name, width / 2, height / 2 - 20);
                
                // Draw "Ready" text
                ctx.fillStyle = '#888';
                ctx.font = '12px monospace';
                ctx.fillText('Ready - Upload audio to start', width / 2, height / 2 + 10);
                
                console.log(`${name} canvas initialized`);
            });
        }
        
        function resizeCanvases() {
            const canvases = [
                { id: 'waterfallCanvas', ctx: waterfallCtx },
                { id: 'neuralCanvas', ctx: neuralCtx },
                { id: 'particleCanvas', ctx: particleCtx },
                { id: 'stereoCanvas', ctx: stereoCtx }
            ];
            
            canvases.forEach(item => {
                const canvas = document.getElementById(item.id);
                if (!canvas) {
                    console.warn(`Canvas ${item.id} not found`);
                    return;
                }
                
                const rect = canvas.getBoundingClientRect();
                if (rect.width === 0 || rect.height === 0) {
                    console.warn(`Canvas ${item.id} has zero size - may not be visible`);
                    // Set default size if not visible
                    canvas.width = 800 * window.devicePixelRatio;
                    canvas.height = 300 * window.devicePixelRatio;
                } else {
                    canvas.width = rect.width * window.devicePixelRatio;
                    canvas.height = rect.height * window.devicePixelRatio || 300 * window.devicePixelRatio;
                }
                
                if (item.ctx) {
                    item.ctx.scale(window.devicePixelRatio, window.devicePixelRatio);
                }
            });
            
            // Re-initialize backgrounds after resize
            if (waterfallCtx && neuralCtx && particleCtx && stereoCtx) {
                initializeCanvasBackgrounds();
            }
        }
        
        function setupEventListeners() {
            const fileInput = document.getElementById('fileInput');
            const uploadZone = document.getElementById('uploadZone');
            const uploadBtn = document.getElementById('uploadBtn');
            
            if (!fileInput) {
                console.error('fileInput element not found!');
                return;
            }
            
            if (!uploadZone) {
                console.error('uploadZone element not found!');
            }
            
            // Set up upload button click handler
            if (uploadBtn) {
                uploadBtn.addEventListener('click', (e) => {
                    e.preventDefault();
                    e.stopPropagation();
                    console.log('Upload button clicked');
                    if (!fileInput) {
                        console.error('File input not found when button clicked!');
                        showError('File input element not found. Please refresh the page.');
                        return;
                    }
                    // Allow selecting the same file twice (otherwise change may not fire)
                    fileInput.value = '';
                    try {
                        fileInput.click();
                        console.log('File input click triggered');
                    } catch (err) {
                        console.error('Error triggering file input click:', err);
                        showError('Error opening file dialog: ' + err.message);
                    }
                });
                console.log('Upload button listener attached');
            } else {
                console.error('Upload button not found!');
            }
            
            // Also make the upload zone clickable
            if (uploadZone) {
                uploadZone.addEventListener('click', (e) => {
                    // Don't hijack clicks inside the AI/provider config box
                    if (e.target && e.target.closest && e.target.closest('.api-key-box')) {
                        return;
                    }
                    // Don't trigger if clicking the button itself
                    if (!uploadBtn || (e.target !== uploadBtn && !uploadBtn.contains(e.target))) {
                        console.log('Upload zone clicked');
                        // Allow selecting the same file twice
                        fileInput.value = '';
                        fileInput.click();
                    }
                });

                // Extra safety: stop propagation from config UI
                const configBox = uploadZone.querySelector('.api-key-box');
                if (configBox) {
                    ['click', 'mousedown', 'mouseup'].forEach(evtName => {
                        configBox.addEventListener(evtName, (ev) => ev.stopPropagation());
                    });
                }
            }
            
            console.log('Setting up file input listener...');
            if (fileInput) {
                fileInput.addEventListener('change', handleFileSelect);
                console.log('File input listener attached successfully');
            } else {
                console.error('Cannot attach file input listener - fileInput is null!');
            }
            
            // Drag and drop
            if (uploadZone) {
                uploadZone.addEventListener('dragover', (e) => {
                    e.preventDefault();
                    uploadZone.classList.add('dragover');
                });
                
                uploadZone.addEventListener('dragleave', () => {
                    uploadZone.classList.remove('dragover');
                });
                
                uploadZone.addEventListener('drop', (e) => {
                    e.preventDefault();
                    uploadZone.classList.remove('dragover');
                    const files = e.dataTransfer.files;
                    if (files.length > 0) {
                        handleFile(files[0]);
                    }
                });
            }

            // Bytez API key UI (upload screen + chat panel)
            wireApiKeyControls({
                inputId: 'bytezKeyInputUpload',
                saveId: 'bytezKeySaveUpload',
                clearId: 'bytezKeyClearUpload'
            });
            wireApiKeyControls({
                inputId: 'bytezKeyInputChat',
                saveId: 'bytezKeySaveChat',
                clearId: 'bytezKeyClearChat'
            });

            // AI audio window selector (clip length vs entire file)
            wireAiAudioWindowControl('aiAudioSendModeUpload');
            wireAiAudioWindowControl('aiAudioSendModeChat');

            // AI provider selector + custom endpoint fields
            wireAiProviderControls();
        }

        function wireAiProviderControls() {
            const selects = [
                document.getElementById('aiProviderSelectUpload'),
                document.getElementById('aiProviderSelectChat')
            ].filter(Boolean);

            const applyUi = () => {
                const provider = (AIConfig.provider || 'bytez');
                selects.forEach(s => { s.value = provider; });

                const showCustom = provider === 'custom';
                const customUpload = document.getElementById('customAiBoxUpload');
                const customChat = document.getElementById('customAiBoxChat');
                const bytezUpload = document.getElementById('bytezAiBoxUpload');
                const bytezChat = document.getElementById('bytezAiBoxChat');
                if (customUpload) customUpload.style.display = showCustom ? '' : 'none';
                if (customChat) customChat.style.display = showCustom ? '' : 'none';
                // Only hide the Bytez *key* row now (audio window selector is always visible)
                if (bytezUpload) bytezUpload.style.display = showCustom ? 'none' : '';
                if (bytezChat) bytezChat.style.display = showCustom ? 'none' : '';
            };

            selects.forEach(sel => {
                sel.addEventListener('change', () => {
                    const v = sel.value === 'custom' ? 'custom' : 'bytez';
                    AIConfig.provider = v;
                    Storage.set('AI_PROVIDER', v);
                    applyUi();
                    initializeAIProvider();
                    updateApiKeyUi();
                });
            });

            // Custom endpoint fields sync
            const setCustomFromUi = () => {
                const chatUrl = (document.getElementById('customAiChatUrlChat')?.value || document.getElementById('customAiChatUrlUpload')?.value || '').trim();
                const authVal = (document.getElementById('customAiAuthHeaderValueChat')?.value || document.getElementById('customAiAuthHeaderValueUpload')?.value || '').trim();
                if (chatUrl) {
                    AIConfig.customChatUrl = chatUrl;
                    Storage.set('AI_CUSTOM_CHAT_URL', chatUrl);
                }
                AIConfig.customAuthHeaderValue = authVal;
                Storage.set('AI_CUSTOM_AUTH_HEADER_VALUE', authVal);
            };

            ['customAiChatUrlUpload','customAiChatUrlChat','customAiAuthHeaderValueUpload','customAiAuthHeaderValueChat'].forEach(id => {
                const el = document.getElementById(id);
                if (!el) return;
                el.addEventListener('change', () => {
                    setCustomFromUi();
                    initializeAIProvider();
                    updateApiKeyUi();
                });
            });

            // Initialize UI with stored values
            const u1 = document.getElementById('customAiChatUrlUpload');
            const u2 = document.getElementById('customAiChatUrlChat');
            if (u1) u1.value = AIConfig.customChatUrl || '';
            if (u2) u2.value = AIConfig.customChatUrl || '';
            const a1 = document.getElementById('customAiAuthHeaderValueUpload');
            const a2 = document.getElementById('customAiAuthHeaderValueChat');
            if (a1) a1.value = AIConfig.customAuthHeaderValue || '';
            if (a2) a2.value = AIConfig.customAuthHeaderValue || '';

            applyUi();
        }

        function wireAiAudioWindowControl(selectId) {
            const el = document.getElementById(selectId);
            if (!el) return;
            el.addEventListener('change', () => {
                setAiAudioWindowSetting(el.value);
                syncAiAudioWindowUi();
                const setting = getAiAudioWindowSetting();
                if (setting.mode === 'full') {
                    showSuccess('AI audio window set to: entire file (may fail if too large)');
                } else {
                    showSuccess(`AI audio window set to: ${setting.seconds}s clip`);
                }
            });
        }

        function wireApiKeyControls({ inputId, saveId, clearId }) {
            const input = document.getElementById(inputId);
            const saveBtn = document.getElementById(saveId);
            const clearBtn = document.getElementById(clearId);
            if (!input || !saveBtn || !clearBtn) return;

            const save = () => {
                const key = (input.value || '').trim();
                if (!key) {
                    showError('Paste a Bytez API key first.');
                    return;
                }
                setBytezApiKey(key);
                input.value = '';
            };

            saveBtn.addEventListener('click', save);
            clearBtn.addEventListener('click', () => {
                clearBytezApiKey();
                input.value = '';
            });
            input.addEventListener('keydown', (e) => {
                if (e.key === 'Enter') save();
            });
        }
        
        // Store selected file before GO is clicked
        let pendingFile = null;
        
        function handleFileSelect(e) {
            console.log('File select event fired', e);
            
            // Get file input element
            const fileInput = e.target || document.getElementById('fileInput');
            
            if (!fileInput) {
                console.error('File input not found!');
                showError('File input element not found. Please refresh the page.');
                return;
            }
            
            // Get the file
            const file = fileInput.files && fileInput.files.length > 0 ? fileInput.files[0] : null;
            
            if (!file) {
                // User cancelled or no file selected
                console.log('No file selected or file dialog cancelled');
                pendingFile = null;
                updateGoButtonState();
                return;
            }
            
            console.log('File selected successfully:', file.name, file.type, file.size);
            
            // Validate file type (be more lenient - check extension if type is missing)
            const fileName = file.name.toLowerCase();
            const validExtensions = ['.mp3', '.wav', '.flac', '.ogg', '.m4a', '.aac', '.aiff', '.webm'];
            const hasValidExtension = validExtensions.some(ext => fileName.endsWith(ext));
            const hasValidType = file.type && file.type.startsWith('audio/');
            
            if (!hasValidType && !hasValidExtension) {
                showError('Please select a valid audio file. Selected file type: ' + (file.type || 'unknown') + ', Extension: ' + fileName.split('.').pop());
                fileInput.value = ''; // Clear the input
                pendingFile = null;
                updateGoButtonState();
                return;
            }
            
            // Store the file for later processing
            pendingFile = file;
            console.log('File stored, waiting for GO button');
            
            // Update UI to show file is ready
            const fileStatus = document.getElementById('fileStatus');
            if (fileStatus) {
                if (AIConfig?.enabled) {
                    fileStatus.textContent = `‚úì File ready: ${file.name}`;
                    fileStatus.style.color = 'var(--success)';
                } else {
                    fileStatus.textContent = `‚úì File selected: ${file.name} ‚Äî AI is not configured`;
                    fileStatus.style.color = 'var(--warning)';
                }
            }
            
            // Enable GO button
            updateGoButtonState();
        }
        
        function updateGoButtonState() {
            const goBtn = document.getElementById('goBtn');
            if (goBtn) {
                const aiReady = !!(AIConfig && AIConfig.enabled);
                if (pendingFile && aiReady) {
                    goBtn.disabled = false;
                    goBtn.style.opacity = '1';
                    goBtn.style.cursor = 'pointer';
                } else {
                    goBtn.disabled = true;
                    goBtn.style.opacity = '0.5';
                    goBtn.style.cursor = 'not-allowed';
                }
            }
        }
        
        // Make startAnalysis globally accessible
        window.startAnalysis = async function startAnalysis() {
            if (!pendingFile) {
                showError('Please select an audio file first');
                return;
            }
            if (!AIConfig?.enabled) {
                showError('AI is required. Configure your AI provider + API key, then re-select the file.');
                return;
            }
            
            console.log('GO button clicked, starting analysis...');
            
            // Disable GO button
            const goBtn = document.getElementById('goBtn');
            if (goBtn) {
                goBtn.disabled = true;
                goBtn.textContent = 'LOADING...';
            }
            
            // Update file status
            const fileStatus = document.getElementById('fileStatus');
            if (fileStatus) {
                fileStatus.textContent = `üîÑ Analyzing: ${pendingFile.name}`;
                fileStatus.style.color = 'var(--info)';
            }
            
            // Show loading state
            const uploadZone = document.getElementById('uploadZone');
            if (uploadZone) {
                uploadZone.classList.add('analyzing');
            }
            
            // Process the file
            try {
                await handleFile(pendingFile);
            } catch (error) {
                console.error('Error in handleFile:', error);
                showError('Error loading file: ' + error.message);
                // Reset UI on error
                if (goBtn) {
                    goBtn.disabled = false;
                    goBtn.textContent = 'GO!';
                }
                if (fileStatus) {
                    fileStatus.textContent = `‚ùå Error: ${error.message}`;
                    fileStatus.style.color = 'var(--error)';
                }
                if (uploadZone) {
                    uploadZone.classList.remove('analyzing');
                }
            }
        }
        
        async function handleFile(file) {
            // Validate file exists and has required properties
            if (!file) {
                console.error('No file provided to handleFile');
                showError('No file provided');
                return;
            }
            
            console.log('handleFile called with:', file.name, file.type, file.size);
            
            // Ensure main layout exists (it contains audio-controls)
            const mainLayout = document.getElementById('mainLayout');
            if (!mainLayout) {
                console.error('Main layout element not found!');
                showError('Main layout element not found. Please refresh the page.');
                return;
            }
            
            // Timeout fallback: show layout after 30 seconds even if analysis hangs
            const timeoutId = setTimeout(() => {
                console.warn('Analysis timeout - showing layout anyway');
                showMainLayout();
            }, 30000);
            
            try {
                console.log('Processing file:', file.name);
                
                // Store the file for Qwen2-Audio analysis
                currentAudioFile = file;
                // Reset cached base64 for Bytez requests
                currentAudioDataUrl = null;
                // Reset cached uploaded URL (new file = new upload needed)
                uploadedFileUrl = null;
                
                // Show loading state
                updatePowerupResults('üéµ Loading audio file and setting up analysis...');
                
                // Initialize audio context if not already done
                if (!audioContext) {
                    console.log('Audio context not initialized, initializing now...');
                    initializeAudio();
                }
                
                // Resume audio context if suspended
                if (audioContext && audioContext.state === 'suspended') {
                    console.log('Resuming suspended audio context...');
                    await audioContext.resume();
                }
                
                // Set up audio element
                console.log('Setting up audio element...');
                setupAudioElement(file);
                
                // Update metadata
                console.log('Updating metadata...');
                updateMetadata(file);
                
                // Show main layout FIRST so canvases exist
                showMainLayout();
                
                // Wait a moment for layout to render, then initialize canvases
                await new Promise(resolve => setTimeout(resolve, 200));
                console.log('Initializing canvases after layout shown...');
                initializeCanvases();
                resizeCanvases();
                
                // Perform upfront AI analysis (AI REQUIRED)
                console.log('Performing upfront AI analysis...');
                if (!AIConfig?.enabled) {
                    throw new Error('AI is not configured');
                }

                try {
                    // Update loading status
                    updatePowerupResults('ü§ñ Analyzing audio with AI...');

                    // Perform all AI analysis upfront with timeout
                    const analysisPromise = fillAllSectionsWithAI();
                    const timeoutPromise = new Promise((_, reject) =>
                        setTimeout(() => reject(new Error('AI analysis timeout')), 25000)
                    );

                    await Promise.race([analysisPromise, timeoutPromise]);

                    // Mark that we've done the upfront analysis
                    hasFilledAISectionsOnce = true;

                    updatePowerupResults('‚úÖ AI analysis complete!');
                } catch (error) {
                    console.error('AI analysis failed:', error);
                    updatePowerupResults(`‚ùå AI analysis failed: ${error.message}`);
                    updateAIAnalysisDisplayError(`AI analysis failed: ${error.message}`);
                    throw error;
                }

                // Clear timeout since we're done
                clearTimeout(timeoutId);
                
                // Layout already shown earlier for canvas initialization
                console.log('Analysis complete!');

                // Add welcome message
                try {
                    addAIMessage(`Audio file "${file.name}" loaded successfully! AI analysis complete! Press play to start real-time visualizations.`);
                } catch (e) {
                    console.warn('Could not add AI message:', e);
                }

                console.log('File processing and analysis complete!');

                // Show success notification
                showSuccess(`Audio file "${file.name}" loaded and analyzed successfully!`);
                
            } catch (error) {
                // Clear timeout
                clearTimeout(timeoutId);
                
                console.error('Error loading audio file:', error);
                console.error('Error stack:', error.stack);
                showError('Error loading audio file: ' + error.message);
                updatePowerupResults('‚ùå Error loading audio file: ' + error.message);
                
                // Do not fall back to non-AI analysis. Keep UI visible for retry/config.
            }
        }
        
        function showMainLayout() {
            console.log('showMainLayout() called');
            const mainLayout = document.getElementById('mainLayout');
            if (!mainLayout) {
                console.error('Main layout element not found when trying to show it!');
                // Try to find it again after a short delay
                setTimeout(() => {
                    const retryLayout = document.getElementById('mainLayout');
                    if (retryLayout) {
                        retryLayout.classList.add('active');
                        retryLayout.style.setProperty('display', 'grid', 'important');
                        console.log('Main layout shown on retry');
                    }
                }, 100);
                return;
            }
            
            // Force show with multiple methods to ensure it works
            mainLayout.classList.add('active');
            mainLayout.style.setProperty('display', 'grid', 'important');
            mainLayout.style.setProperty('visibility', 'visible', 'important');
            mainLayout.style.setProperty('opacity', '1', 'important');
            mainLayout.removeAttribute('hidden');
            console.log('Main layout shown - display:', mainLayout.style.display, 'classList:', mainLayout.classList.toString());

            // Hide upload zone now that analysis is done
            const uploadZone = document.getElementById('uploadZone');
            if (uploadZone) {
                uploadZone.classList.add('hidden');
                uploadZone.setAttribute('hidden', 'true');
                uploadZone.style.display = 'none';
                uploadZone.style.visibility = 'hidden';
                console.log('Upload zone hidden');
            } else {
                console.warn('Upload zone not found');
            }
            
            // Scroll to top to show the main content
            window.scrollTo({ top: 0, behavior: 'smooth' });
        }
        
        function setupAudioElement(file) {
            // Create or reset audio element
            let existingAudio = document.getElementById('audioPlayer');
            
            // Stop any existing analysis
            stopRealTimeAnalysis();
            
            // Clean up existing MediaElementSource if it exists
            if (mediaSource) {
                try {
                    mediaSource.disconnect();
                    mediaSource = null;
                } catch (e) {
                    console.warn('Error disconnecting existing media source:', e);
                }
            }
            
            // Create new audio element
            const newAudioElement = document.createElement('audio');
            newAudioElement.id = 'audioPlayer';
            newAudioElement.controls = true;
            newAudioElement.style.width = '100%';
            
            // Replace existing or insert new
            if (existingAudio && existingAudio.parentNode) {
                const parent = existingAudio.parentNode;
                parent.replaceChild(newAudioElement, existingAudio);
            } else {
                // Find audio controls container and insert
                const audioControls = document.querySelector('.audio-controls');
                if (audioControls) {
                    // Remove any existing audio element first
                    const oldAudio = audioControls.querySelector('audio');
                    if (oldAudio) {
                        oldAudio.remove();
                    }
                    audioControls.insertBefore(newAudioElement, audioControls.firstChild);
                } else {
                    console.error('Audio controls container not found!');
                    showError('Audio player container not found. Please refresh the page.');
                    return;
                }
            }
            
            audioElement = newAudioElement;
            
            // Create object URL for the file
            const url = URL.createObjectURL(file);
            audioElement.src = url;
            
            // Set up event listeners with better error handling
            audioElement.addEventListener('loadedmetadata', async () => {
                console.log('Audio metadata loaded, duration:', audioElement.duration);
                // Ensure audio context is resumed before setting up graph
                if (audioContext && audioContext.state === 'suspended') {
                    try {
                        await audioContext.resume();
                        console.log('Audio context resumed for graph setup');
                    } catch (e) {
                        console.error('Failed to resume audio context:', e);
                    }
                }
                setupWebAudioGraph();
            });
            
            audioElement.addEventListener('canplaythrough', () => {
                console.log('Audio can play through');
            });
            
            audioElement.addEventListener('play', async () => {
                console.log('Audio play event fired');
                // Ensure audio context is running
                if (audioContext && audioContext.state === 'suspended') {
                    try {
                        await audioContext.resume();
                        console.log('Audio context resumed on play, state:', audioContext.state);
                    } catch (e) {
                        console.error('Failed to resume audio context:', e);
                    }
                }
                // Small delay to ensure audio is actually playing
                setTimeout(() => {
                    startRealTimeAnalysis();
                }, 100);
            });
            
            audioElement.addEventListener('pause', () => {
                console.log('Audio pause event fired');
                stopRealTimeAnalysis();
            });
            
            audioElement.addEventListener('ended', () => {
                console.log('Audio ended event fired');
                stopRealTimeAnalysis();
            });
            
            audioElement.addEventListener('timeupdate', () => {
                if (audioElement && !audioElement.paused && !audioElement.ended && frequencyData) {
                    updateRealTimeScores();
                }
            });
            
            audioElement.addEventListener('error', (e) => {
                console.error('Audio element error:', e);
                showError('Error loading audio file');
            });
            
            // Preload the audio
            audioElement.load();
        }
        
        function setupWebAudioGraph() {
            try {
                console.log('Setting up Web Audio graph...');
                
                // Ensure audio context is running
                if (audioContext.state === 'suspended') {
                    console.log('Audio context suspended, will resume on user interaction');
                }
                
                // Clean up existing connections
                if (mediaSource) {
                    console.log('Disconnecting existing media source');
                    try {
                        mediaSource.disconnect();
                    } catch (e) {
                        console.warn('Error disconnecting media source:', e);
                    }
                    mediaSource = null;
                }
                
                // Check if MediaElementSource already exists (can only create once per element)
                if (!audioElement || !audioContext) {
                    console.error('Audio element or context not available');
                    return;
                }
                
                // Create media element source (can only be done once per audio element)
                console.log('Creating MediaElementSource...');
                try {
                    mediaSource = audioContext.createMediaElementSource(audioElement);
                } catch (error) {
                    if (error.name === 'InvalidStateError') {
                        console.error('MediaElementSource already exists for this element');
                        showError('Audio source already initialized. Please reload the page.');
                        return;
                    }
                    throw error;
                }
                
                // Create main analyser
                console.log('Creating main analyser...');
                analyserNode = audioContext.createAnalyser();
                analyserNode.fftSize = 4096; // Reduced for better performance
                analyserNode.smoothingTimeConstant = 0.8;
                
                // Create stereo analyser
                console.log('Creating stereo analysers...');
                splitterNode = audioContext.createChannelSplitter(2);
                leftAnalyser = audioContext.createAnalyser();
                rightAnalyser = audioContext.createAnalyser();
                leftAnalyser.fftSize = 1024; // Reduced for performance
                rightAnalyser.fftSize = 1024;
                leftAnalyser.smoothingTimeConstant = 0.8;
                rightAnalyser.smoothingTimeConstant = 0.8;
                
                // Connect the audio graph
                console.log('Connecting audio graph...');
                mediaSource.connect(analyserNode);
                mediaSource.connect(splitterNode);
                splitterNode.connect(leftAnalyser, 0);
                splitterNode.connect(rightAnalyser, 1);
                setupIsolationPlaybackChain();
                
                console.log('Audio graph connected successfully');
                console.log('MediaSource connected to:', {
                    analyser: !!analyserNode,
                    splitter: !!splitterNode,
                    destination: !!audioContext.destination
                });
                
                // Initialize data arrays
                frequencyData = new Uint8Array(analyserNode.frequencyBinCount);
                timeData = new Uint8Array(analyserNode.frequencyBinCount);
                leftFreqData = new Uint8Array(leftAnalyser.frequencyBinCount);
                rightFreqData = new Uint8Array(rightAnalyser.frequencyBinCount);
                
                console.log('Web Audio graph setup complete!');
                console.log('Main FFT Size:', analyserNode.fftSize, 'Frequency bins:', analyserNode.frequencyBinCount);
                console.log('Stereo FFT Size:', leftAnalyser.fftSize, 'Stereo bins:', leftAnalyser.frequencyBinCount);
                
                // Test data collection periodically
                const testInterval = setInterval(() => {
                    if (analyserNode && frequencyData && audioElement && !audioElement.paused) {
                        analyserNode.getByteFrequencyData(frequencyData);
                        const sum = frequencyData.reduce((a, b) => a + b, 0);
                        if (sum > 0) {
                            console.log('‚úÖ Audio data flowing! Frequency data sum:', sum);
                            clearInterval(testInterval);
                        } else {
                            console.log('‚ö†Ô∏è No audio data detected yet (audio might not be playing)');
                        }
                    }
                }, 500);
                
                // Stop testing after 10 seconds
                setTimeout(() => clearInterval(testInterval), 10000);
                
            } catch (error) {
                console.error('Error setting up Web Audio graph:', error);
                showError('Error setting up audio analysis: ' + error.message);
            }
        }

        function setupIsolationPlaybackChain() {
            if (!audioContext || !mediaSource) return;
            // Create (or recreate) the playback chain that feeds the speakers.
            // This lets Power-Ups apply ‚Äúisolation‚Äù filters in a real, working way.
            if (isolationInputGain) {
                try { isolationInputGain.disconnect(); } catch {}
            }
            isolationFilters.forEach(n => { try { n.disconnect(); } catch {} });
            isolationFilters = [];

            isolationInputGain = audioContext.createGain();
            isolationInputGain.gain.value = 1.0;

            isolationDryGain = audioContext.createGain();
            isolationWetGain = audioContext.createGain();
            // default: dry only until an isolation mode is chosen
            isolationMix = (isolationMode === 'full') ? 0.0 : 1.0;
            setIsolationMix(isolationMix, { silent: true });

            try {
                mediaSource.connect(isolationInputGain);
            } catch (e) {
                console.warn('Failed to connect mediaSource to isolationInputGain:', e);
            }

            // Always keep a dry path so user can mix it in
            try {
                isolationInputGain.connect(isolationDryGain);
                isolationDryGain.connect(audioContext.destination);
            } catch (e) {
                console.warn('Failed to connect dry path:', e);
            }

            // Apply current mode
            applyIsolationMode(isolationMode, { silent: true });
        }

        function setIsolationMix(value, { silent = false } = {}) {
            const v = Math.max(0, Math.min(1, Number(value)));
            isolationMix = Number.isFinite(v) ? v : 1.0;
            if (isolationDryGain) isolationDryGain.gain.value = 1 - isolationMix;
            if (isolationWetGain) isolationWetGain.gain.value = isolationMix;
            if (!silent) showSuccess(`Isolation mix: ${Math.round(isolationMix * 100)}%`);
        }

        function applyIsolationMode(mode = 'full', { silent = false } = {}) {
            if (!audioContext || !isolationInputGain) return;
            isolationMode = mode;

            // Disconnect existing filter chain safely
            // Do NOT disconnect dry path here; only rebuild wet chain.
            isolationFilters.forEach(n => { try { n.disconnect(); } catch {} });
            isolationFilters = [];

            const connectChain = (nodes) => {
                if (!isolationWetGain) return;
                // Connect: mediaSource -> isolationInputGain -> ...nodes... -> isolationWetGain -> destination
                let prev = isolationInputGain;
                nodes.forEach(n => {
                    prev.connect(n);
                    prev = n;
                });
                prev.connect(isolationWetGain);
                isolationWetGain.connect(audioContext.destination);
            };

            if (mode === 'full') {
                // No wet chain; dry only
                setIsolationMix(0.0, { silent: true });
            } else if (mode === 'bass') {
                const lp = audioContext.createBiquadFilter();
                lp.type = 'lowpass';
                lp.frequency.value = 220;
                lp.Q.value = 0.7;
                isolationFilters = [lp];
                connectChain(isolationFilters);
                setIsolationMix(1.0, { silent: true });
            } else if (mode === 'vocals') {
                // ‚ÄúVocal-ish‚Äù band: 300‚Äì3400 Hz
                const hp = audioContext.createBiquadFilter();
                hp.type = 'highpass';
                hp.frequency.value = 280;
                hp.Q.value = 0.7;
                const lp = audioContext.createBiquadFilter();
                lp.type = 'lowpass';
                lp.frequency.value = 3600;
                lp.Q.value = 0.7;
                isolationFilters = [hp, lp];
                connectChain(isolationFilters);
                setIsolationMix(1.0, { silent: true });
            } else if (mode === 'drums') {
                // ‚ÄúDrums-ish‚Äù emphasis: remove sub + brighten attack a bit
                const hp = audioContext.createBiquadFilter();
                hp.type = 'highpass';
                hp.frequency.value = 70;
                hp.Q.value = 0.7;
                const presence = audioContext.createBiquadFilter();
                presence.type = 'peaking';
                presence.frequency.value = 2500;
                presence.Q.value = 1.0;
                presence.gain.value = 6.0;
                const lp = audioContext.createBiquadFilter();
                lp.type = 'lowpass';
                lp.frequency.value = 9000;
                lp.Q.value = 0.7;
                isolationFilters = [hp, presence, lp];
                connectChain(isolationFilters);
                setIsolationMix(1.0, { silent: true });
            } else if (mode === 'instruments') {
                // Mid band emphasis (guitars/keys): 160‚Äì7000 Hz
                const hp = audioContext.createBiquadFilter();
                hp.type = 'highpass';
                hp.frequency.value = 160;
                hp.Q.value = 0.7;
                const lp = audioContext.createBiquadFilter();
                lp.type = 'lowpass';
                lp.frequency.value = 7000;
                lp.Q.value = 0.7;
                isolationFilters = [hp, lp];
                connectChain(isolationFilters);
                setIsolationMix(1.0, { silent: true });
            } else {
                // Unknown mode: fallback
                setIsolationMix(0.0, { silent: true });
            }

            if (!silent) {
                showSuccess(`Isolation preview: ${mode}`);
            }
        }
        
        async function startRealTimeAnalysis() {
            if (!analyserNode || !frequencyData) {
                console.warn('Audio analysis not ready - analyser:', !!analyserNode, 'frequencyData:', !!frequencyData);
                return;
            }
            
            if (!audioElement) {
                console.warn('Audio element not available');
                return;
            }
            
            console.log('Starting real-time analysis...');
            console.log('Audio element state - paused:', audioElement.paused, 'ended:', audioElement.ended);
            isPlaying = true;
            
            // Resume audio context if needed
            if (audioContext && audioContext.state === 'suspended') {
                console.log('Resuming suspended audio context...');
                try {
                    await audioContext.resume();
                    console.log('Audio context resumed, state:', audioContext.state);
                } catch (error) {
                    console.error('Failed to resume audio context:', error);
                    showError('Failed to start audio analysis');
                    return;
                }
            }
            
            // Wait a moment for audio to start playing
            await new Promise(resolve => setTimeout(resolve, 200));
            
            // Test frequency data collection
            analyserNode.getByteFrequencyData(frequencyData);
            const dataSum = frequencyData.reduce((a, b) => a + b, 0);
            console.log('Initial frequency data check - sum:', dataSum, 'sample:', frequencyData.slice(0, 10));
            
            if (dataSum === 0) {
                console.warn('No audio data detected - make sure audio is playing');
            }
            
            // Ensure visualization loops are running (they may have been cancelled previously)
            if (!animationFrames || typeof animationFrames !== 'object') {
                animationFrames = {};
            }
            if (!animationFrames.waterfall) animateWaterfall();
            if (!animationFrames.neural) animateNeuralNetwork();
            if (!animationFrames.particles) animateParticles();
            if (!animationFrames.stereo) animateStereoField();
            console.log('Visualizations ensured running');
            
            // Start AI analysis if enabled
            startAIAnalysis(5000); // Analyze every 5 seconds

            // AI analysis now happens upfront during file upload, not during playback
        }
        
        function stopRealTimeAnalysis() {
            isPlaying = false;
            console.log('Stopping real-time analysis');
            
            // Do NOT cancel visualization loops.
            // They are designed to keep running and render an idle state when audio is paused/stopped.
            // Only stop periodic AI analysis below.

            // Stop AI analysis
            stopAIAnalysis();
        }
        
        function updateMetadata(file) {
            const metadata = document.getElementById('metadata');
            const fileSize = (file.size / (1024 * 1024)).toFixed(2);
            
            metadata.innerHTML = `
                <div class="metadata-card">
                    <div class="metadata-label">Filename</div>
                    <div class="metadata-value">${file.name.length > 15 ? file.name.substring(0, 15) + '...' : file.name}</div>
                </div>
                <div class="metadata-card">
                    <div class="metadata-label">Size</div>
                    <div class="metadata-value">${fileSize} MB</div>
                </div>
                <div class="metadata-card">
                    <div class="metadata-label">Type</div>
                    <div class="metadata-value">${file.type.split('/')[1].toUpperCase()}</div>
                </div>
            `;
        }
        
        async function performInitialAnalysis() {
            // Only used as fallback when AI analysis fails or is disabled
            // AI analysis now happens upfront in handleFile
                generatePsychologicalAnalysis();
                generateNarrativeAnalysis();
                generateTechnicalAnalysis();
                generateCulturalAnalysis();
                generateGamingAnalysis();
                generateGenreAnalysis();
        }

        function showAiSectionPlaceholders() {
            const ids = [
                'psychological-cards',
                'narrative-cards',
                'technical-cards',
                'cultural-cards',
                'gaming-cards',
                'genre-cards',
            ];
            ids.forEach(id => {
                const el = document.getElementById(id);
                if (!el) return;
                el.innerHTML = `
                    <div class="analysis-card">
                        <div class="card-header">
                            <div class="card-title">AI ready</div>
                            <div class="card-score medium">--</div>
                        </div>
                        <div class="card-description">
                            Press <strong>Play</strong> to capture the selected AI audio window and fill this section automatically.
                        </div>
                    </div>
                `;
            });
        }

        async function fillAllSectionsWithAI() {
            await Promise.allSettled([
                fillCardsFromAI('psychological-cards', 'psychological'),
                fillCardsFromAI('narrative-cards', 'narrative'),
                fillCardsFromAI('technical-cards', 'technical'),
                fillCardsFromAI('cultural-cards', 'cultural'),
                fillCardsFromAI('gaming-cards', 'gaming'),
                fillCardsFromAI('genre-cards', 'genre'),
            ]);
        }

        function renderCards(containerId, cards) {
            const el = document.getElementById(containerId);
            if (!el) return;
            const scoreClass = (s) => (s >= 80 ? 'high' : s >= 60 ? 'medium' : 'low');

            el.innerHTML = `
                <div style="display:flex; justify-content: flex-end; margin-bottom: 10px;">
                    <button class="control-btn" style="padding: 6px 10px; font-size: 0.75em;" onclick="refreshSection('${containerId}')">‚Üª Refresh</button>
                </div>
            ` + cards.map(c => {
                const score = typeof c.score === 'number' ? Math.max(0, Math.min(100, Math.round(c.score))) : 0;
                const title = escapeHtml(String(c.title || 'AI Insight'));
                const desc = escapeHtml(String(c.description || ''));
                return `
                    <div class="analysis-card">
                        <div class="card-header">
                            <div class="card-title">${title}</div>
                            <div class="card-score ${scoreClass(score)}">${score}/100</div>
                        </div>
                        <div class="card-description">${desc}</div>
                    </div>
                `;
            }).join('');
        }

        const SECTION_ID_TO_TYPE = {
            'psychological-cards': 'psychological',
            'narrative-cards': 'narrative',
            'technical-cards': 'technical',
            'cultural-cards': 'cultural',
            'gaming-cards': 'gaming',
            'genre-cards': 'genre',
        };

        function refreshSection(containerId) {
            const type = SECTION_ID_TO_TYPE[containerId];
            if (!type) return;
            if (!AIConfig.enabled) {
                showError('Configure AI first (provider + key/endpoint).');
                return;
            }
            fillCardsFromAI(containerId, type).catch(() => {});
        }

        function escapeHtml(str) {
            return str
                .replace(/&/g, '&amp;')
                .replace(/</g, '&lt;')
                .replace(/>/g, '&gt;')
                .replace(/"/g, '&quot;')
                .replace(/'/g, '&#039;');
        }

        function extractJsonObject(text) {
            if (!text) return null;
            // Try fenced ```json
            const fenced = text.match(/```json\\s*([\\s\\S]*?)```/i);
            const candidate = fenced ? fenced[1] : text;
            const start = candidate.indexOf('{');
            const end = candidate.lastIndexOf('}');
            if (start === -1 || end === -1 || end <= start) return null;
            const slice = candidate.slice(start, end + 1);
            try { return JSON.parse(slice); } catch { return null; }
        }

        async function fillCardsFromAI(containerId, analysisType) {
            const el = document.getElementById(containerId);
            if (!el) return;
            el.innerHTML = `
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">AI is analyzing‚Ä¶</div>
                        <div class="card-score medium">--</div>
                    </div>
                    <div class="card-description">Generating ${analysisType} insights from the track audio.</div>
                </div>
            `;

            const result = await analyzeWithAI(analysisType);
            if (!result?.analysis) {
                el.innerHTML = `
                    <div class="analysis-card">
                        <div class="card-header">
                            <div class="card-title">AI unavailable</div>
                            <div class="card-score low">--</div>
                        </div>
                        <div class="card-description">Configure a Bytez API key to fill this section.</div>
                    </div>
                `;
                return;
            }

            // Parse cards from JSON; if it failed, retry once with a stricter prompt.
            let parsed = extractJsonObject(result.analysis);
            if (!(parsed?.cards && Array.isArray(parsed.cards) && parsed.cards.length)) {
                const strictPrompt =
                    `Return ONLY valid minified JSON with this schema: {"cards":[{"title":"string","score":0-100,"description":"string"}]}. ` +
                    `No markdown, no code fences, no extra keys. ` +
                    `Cards count rules: psychological=3, narrative/cultural/gaming=2-3, technical=2-4, genre=2-5.`;
                const retry = await analyzeWithAI(analysisType, strictPrompt);
                parsed = extractJsonObject(retry?.analysis || '');
            }

            if (parsed?.cards && Array.isArray(parsed.cards) && parsed.cards.length) {
                renderCards(containerId, parsed.cards.slice(0, 5));
                return;
            }

            // Last resort: show raw text in a single card (should be rare now)
            renderCards(containerId, [
                { title: 'AI Analysis', score: 80, description: result.analysis }
            ]);
        }
        
        // Real-time Waterfall Visualization
        function animateWaterfall() {
            // Always continue the animation loop
            animationFrames.waterfall = requestAnimationFrame(animateWaterfall);
            
            // Check if we have what we need
            if (!waterfallCtx) {
                console.warn('Waterfall canvas context not available');
                return;
            }
            
            const canvas = waterfallCtx.canvas;
            if (!canvas) {
                return;
            }
            
            const width = canvas.width / window.devicePixelRatio;
            const height = canvas.height / window.devicePixelRatio;
            
            // If analyser isn't ready yet, show waiting state
            if (!analyserNode || !frequencyData) {
                // Draw subtle animation to show it's working
                const time = Date.now() / 1000;
                waterfallCtx.fillStyle = '#0a0a0a';
                waterfallCtx.fillRect(0, 0, width, height);
                
                // Draw pulsing dot
                waterfallCtx.fillStyle = `rgba(0, 255, 136, ${0.3 + Math.sin(time * 2) * 0.2})`;
                waterfallCtx.beginPath();
                waterfallCtx.arc(width / 2, height / 2, 5 + Math.sin(time * 3) * 3, 0, Math.PI * 2);
                waterfallCtx.fill();
                return;
            }
            
            // Get real frequency data
            analyserNode.getByteFrequencyData(frequencyData);
            
            // Check if audio is actually playing
            const isAudioPlaying = audioElement && !audioElement.paused && !audioElement.ended;
            
            // Debug: Log frequency data occasionally when playing
            if (isAudioPlaying && Math.random() < 0.01) {
                const sum = frequencyData.reduce((a, b) => a + b, 0);
                console.log('Waterfall - Audio playing! Frequency data sum:', sum, 'sample:', frequencyData.slice(0, 5));
            }
            
            // ALWAYS shift the waterfall down (creates scrolling effect)
            waterfallCtx.drawImage(canvas, 0, 0, width, height - 2, 0, 2, width, height - 2);
            
            // Clear the top 2 rows for new data
            waterfallCtx.fillStyle = 'rgba(0, 0, 0, 0.1)';
            waterfallCtx.fillRect(0, 0, width, 2);
            
            // Draw frequency data - use actual data if playing, otherwise draw zeros
            const barWidth = width / frequencyData.length;
            
            for (let i = 0; i < frequencyData.length; i++) {
                // Use real frequency data if audio is playing, otherwise use 0
                const rawValue = isAudioPlaying ? frequencyData[i] : 0;
                const value = rawValue / 255;
                
                // Create color based on frequency intensity
                let hue, saturation, lightness;
                
                if (waterfallMode === '3d') {
                    hue = (value * 120) + 240; // Blue to green spectrum
                    saturation = 100;
                    lightness = Math.min(value * 80 + 20, 90);
                } else {
                    hue = (i / frequencyData.length) * 360; // Rainbow spectrum
                    saturation = value * 100;
                    lightness = Math.min(value * 60 + 30, 80);
                }
                
                waterfallCtx.fillStyle = `hsl(${hue}, ${saturation}%, ${lightness}%)`;
                waterfallCtx.fillRect(i * barWidth, 0, Math.ceil(barWidth), 2);
            }
            
            // Add 3D perspective lines in 3D mode
            if (waterfallMode === '3d') {
                waterfallCtx.strokeStyle = 'rgba(0, 255, 136, 0.2)';
                waterfallCtx.lineWidth = 0.5;
                for (let i = 0; i < width; i += 40) {
                    waterfallCtx.beginPath();
                    waterfallCtx.moveTo(i, 0);
                    waterfallCtx.lineTo(i, height);
                    waterfallCtx.stroke();
                }
            }
            
            // Animation loop continues at the start of the function
        }
        
        // Neural Network Visualization
        function setupNeuralNetwork() {
            neuralNodes = [];
            neuralConnections = [];
            
            const width = 400;
            const height = 300;
            
            // Create input layer (32 nodes)
            for (let i = 0; i < 32; i++) {
                neuralNodes.push({
                    x: 50,
                    y: (i / 31) * (height - 40) + 20,
                    layer: 'input',
                    activation: 0,
                    id: i
                });
            }
            
            // Create hidden layers
            for (let layer = 0; layer < 3; layer++) {
                const nodeCount = layer === 1 ? 16 : 8;
                for (let i = 0; i < nodeCount; i++) {
                    neuralNodes.push({
                        x: 150 + layer * 100,
                        y: (i / (nodeCount - 1)) * (height - 80) + 40,
                        layer: 'hidden',
                        activation: 0,
                        id: `h${layer}_${i}`
                    });
                }
            }
            
            // Create output layer (5 nodes for different analysis types)
            for (let i = 0; i < 5; i++) {
                neuralNodes.push({
                    x: 350,
                    y: (i / 4) * (height - 100) + 50,
                    layer: 'output',
                    activation: 0,
                    id: `output_${i}`
                });
            }
            
            // Create connections
            neuralNodes.forEach(node => {
                if (node.layer !== 'output') {
                    neuralNodes.forEach(target => {
                        if ((node.layer === 'input' && target.layer === 'hidden' && target.x === 150) ||
                            (node.layer === 'hidden' && target.layer === 'hidden' && target.x > node.x) ||
                            (node.layer === 'hidden' && target.layer === 'output')) {
                            neuralConnections.push({
                                from: node,
                                to: target,
                                weight: Math.random() * 2 - 1,
                                activity: 0
                            });
                        }
                    });
                }
            });
        }
        
        // Real-time Neural Network Visualization
        function animateNeuralNetwork() {
            // Always continue the animation loop
            animationFrames.neural = requestAnimationFrame(animateNeuralNetwork);
            
            // Check if we have what we need
            if (!neuralCtx) {
                return;
            }
            
            const canvas = neuralCtx.canvas;
            if (!canvas) {
                return;
            }
            
            const width = canvas.width / window.devicePixelRatio;
            const height = canvas.height / window.devicePixelRatio;
            
            // If analyser isn't ready yet, show waiting state
            if (!analyserNode || !frequencyData) {
                neuralCtx.fillStyle = '#0a0a0a';
                neuralCtx.fillRect(0, 0, width, height);
                
                // Draw network structure preview
                neuralCtx.strokeStyle = 'rgba(0, 255, 136, 0.2)';
                neuralCtx.lineWidth = 1;
                // Draw some preview lines
                for (let i = 0; i < 5; i++) {
                    neuralCtx.beginPath();
                    neuralCtx.moveTo(50, 50 + i * 50);
                    neuralCtx.lineTo(350, 100 + i * 30);
                    neuralCtx.stroke();
                }
                return;
            }
            
            // Get real frequency data
            analyserNode.getByteFrequencyData(frequencyData);
            
            // Check if audio is actually playing
            const isAudioPlaying = audioElement && !audioElement.paused && !audioElement.ended;
            
            // Clear canvas with slight fade
            neuralCtx.fillStyle = 'rgba(0, 0, 0, 0.03)';
            neuralCtx.fillRect(0, 0, width, height);
            
            // Update input layer with real frequency data (use zeros if not playing)
            for (let i = 0; i < Math.min(32, neuralNodes.length); i++) {
                // Map frequency bins to input nodes
                const freqBinSize = Math.floor(frequencyData.length / 32);
                const startBin = i * freqBinSize;
                const endBin = Math.min(startBin + freqBinSize, frequencyData.length);
                
                // Average frequency data for this input node
                let avgValue = 0;
                if (isAudioPlaying) {
                    for (let j = startBin; j < endBin; j++) {
                        avgValue += frequencyData[j];
                    }
                    avgValue = (avgValue / (endBin - startBin)) / 255;
                } else {
                    avgValue = 0; // No activation when not playing
                }
                
                if (neuralNodes[i]) {
                    neuralNodes[i].activation = avgValue;
                }
            }
            
            // Propagate activation through network layers
            neuralNodes.forEach(node => {
                if (node.layer !== 'input') {
                    let sum = 0;
                    let connectionCount = 0;
                    
                    neuralConnections.forEach(conn => {
                        if (conn.to === node) {
                            sum += conn.from.activation * Math.abs(conn.weight);
                            connectionCount++;
                        }
                    });
                    
                    // Apply activation function
                    if (connectionCount > 0) {
                        const rawActivation = sum / connectionCount;
                        node.activation = Math.tanh(rawActivation * 2); // More responsive
                    }
                }
            });
            
            // Update connection activities
            neuralConnections.forEach(conn => {
                conn.activity = Math.min(conn.from.activation * Math.abs(conn.weight) * 0.8, 1);
            });
            
            // Draw connections with real-time intensity
            neuralConnections.forEach(conn => {
                const opacity = conn.activity;
                if (opacity > 0.05) {
                    const lineWidth = 0.5 + conn.activity * 3;
                    
                    neuralCtx.beginPath();
                    neuralCtx.moveTo(conn.from.x, conn.from.y);
                    neuralCtx.lineTo(conn.to.x, conn.to.y);
                    
                    // Color based on activity level
                    if (conn.activity > 0.7) {
                        neuralCtx.strokeStyle = `rgba(255, 107, 107, ${opacity})`; // Red for high activity
                    } else if (conn.activity > 0.4) {
                        neuralCtx.strokeStyle = `rgba(255, 165, 0, ${opacity})`; // Orange for medium
                    } else {
                        neuralCtx.strokeStyle = `rgba(0, 255, 136, ${opacity})`; // Green for low
                    }
                    
                    neuralCtx.lineWidth = lineWidth;
                    neuralCtx.stroke();
                }
            });
            
            // Draw nodes with real-time activation
            neuralNodes.forEach(node => {
                const baseSize = 3;
                const size = baseSize + (node.activation * 8);
                
                // Color based on layer and activation
                let hue, saturation, lightness;
                if (node.layer === 'input') {
                    hue = 180; // Cyan
                    saturation = 100;
                    lightness = 30 + (node.activation * 50);
                } else if (node.layer === 'hidden') {
                    hue = 120; // Green  
                    saturation = 100;
                    lightness = 25 + (node.activation * 60);
                } else { // output
                    hue = 60; // Yellow
                    saturation = 100;
                    lightness = 30 + (node.activation * 55);
                }
                
                // Draw node body
                neuralCtx.beginPath();
                neuralCtx.arc(node.x, node.y, size, 0, Math.PI * 2);
                neuralCtx.fillStyle = `hsl(${hue}, ${saturation}%, ${lightness}%)`;
                neuralCtx.fill();
                
                // Add glow effect for high activation
                if (node.activation > 0.6) {
                    neuralCtx.strokeStyle = `hsl(${hue}, 100%, 80%)`;
                    neuralCtx.lineWidth = 2;
                    neuralCtx.stroke();
                    
                    // Extra glow
                    neuralCtx.beginPath();
                    neuralCtx.arc(node.x, node.y, size + 2, 0, Math.PI * 2);
                    neuralCtx.strokeStyle = `hsla(${hue}, 100%, 90%, 0.3)`;
                    neuralCtx.lineWidth = 1;
                    neuralCtx.stroke();
                }
            });
            
            // Draw layer labels
            neuralCtx.font = '10px JetBrains Mono';
            neuralCtx.fillStyle = 'rgba(255, 255, 255, 0.7)';
            neuralCtx.fillText('INPUT', 20, 15);
            neuralCtx.fillText('HIDDEN', 140, 15);
            neuralCtx.fillText('ANALYSIS', 290, 15);
            
            // Animation loop continues at the start of the function
        }
        
        // Particle System
        function initializeParticles() {
            particles = [];
            for (let i = 0; i < 150; i++) {
                particles.push({
                    x: Math.random() * 400,
                    y: Math.random() * 300,
                    vx: (Math.random() - 0.5) * 2,
                    vy: (Math.random() - 0.5) * 2,
                    size: Math.random() * 3 + 1,
                    life: 1,
                    maxLife: Math.random() * 100 + 50,
                    frequency: Math.floor(Math.random() * 32) // Which frequency band to react to
                });
            }
        }
        
        // Real-time Particle System
        function animateParticles() {
            // Always continue the animation loop
            animationFrames.particles = requestAnimationFrame(animateParticles);
            
            // Check if we have what we need
            if (!particleCtx) {
                return;
            }
            
            const canvas = particleCtx.canvas;
            if (!canvas) {
                return;
            }
            
            const width = canvas.width / window.devicePixelRatio;
            const height = canvas.height / window.devicePixelRatio;
            
            // If analyser isn't ready yet, show waiting state
            if (!analyserNode || !frequencyData) {
                particleCtx.fillStyle = 'rgba(0, 0, 0, 0.08)';
                particleCtx.fillRect(0, 0, width, height);
                
                // Draw some static particles
                const time = Date.now() / 1000;
                for (let i = 0; i < 10; i++) {
                    particleCtx.fillStyle = `rgba(0, 255, 136, ${0.3 + Math.sin(time + i) * 0.2})`;
                    particleCtx.beginPath();
                    particleCtx.arc(
                        (width / 10) * i + Math.sin(time + i) * 10,
                        height / 2 + Math.cos(time + i) * 20,
                        3, 0, Math.PI * 2
                    );
                    particleCtx.fill();
                }
                return;
            }
            
            // Get real frequency data
            analyserNode.getByteFrequencyData(frequencyData);
            
            // Check if audio is actually playing
            const isAudioPlaying = audioElement && !audioElement.paused && !audioElement.ended;
            
            // Clear canvas with trail effect
            particleCtx.fillStyle = 'rgba(0, 0, 0, 0.08)';
            particleCtx.fillRect(0, 0, width, height);
            
            // Calculate frequency bands (use zeros if not playing)
            const bassRange = frequencyData.slice(0, Math.floor(frequencyData.length * 0.1));
            const midRange = frequencyData.slice(Math.floor(frequencyData.length * 0.1), Math.floor(frequencyData.length * 0.5));
            const highRange = frequencyData.slice(Math.floor(frequencyData.length * 0.5));
            
            const bassAvg = isAudioPlaying ? (bassRange.reduce((a, b) => a + b, 0) / bassRange.length / 255) : 0;
            const midAvg = isAudioPlaying ? (midRange.reduce((a, b) => a + b, 0) / midRange.length / 255) : 0;
            const highAvg = isAudioPlaying ? (highRange.reduce((a, b) => a + b, 0) / highRange.length / 255) : 0;
            
            particles.forEach((particle, index) => {
                // Get frequency data for this particle's assigned frequency band
                const freqBand = Math.floor((particle.frequency / 150) * frequencyData.length);
                const intensity = isAudioPlaying ? (frequencyData[freqBand] / 255) : 0;
                
                // Update particle based on real audio intensity
                const energyMultiplier = 1 + (intensity * 3);
                
                // Apply forces based on frequency content
                if (particleMode === 'frequency') {
                    particle.vx += (Math.random() - 0.5) * intensity * 0.8;
                    particle.vy += (Math.random() - 0.5) * intensity * 0.8;
                } else if (particleMode === 'energy') {
                    const totalEnergy = (bassAvg + midAvg + highAvg) / 3;
                    particle.vx += (Math.random() - 0.5) * totalEnergy * 1.2;
                    particle.vy += (Math.random() - 0.5) * totalEnergy * 1.2;
                } else if (particleMode === 'chaos') {
                    // High frequencies create chaotic movement
                    particle.vx += (Math.random() - 0.5) * highAvg * 2;
                    particle.vy += (Math.random() - 0.5) * highAvg * 2;
                }
                
                // Update position
                particle.x += particle.vx;
                particle.y += particle.vy;
                
                // Bounce off walls with energy loss
                if (particle.x < 0 || particle.x > width) {
                    particle.vx *= -0.7;
                    particle.x = Math.max(0, Math.min(width, particle.x));
                }
                if (particle.y < 0 || particle.y > height) {
                    particle.vy *= -0.7;
                    particle.y = Math.max(0, Math.min(height, particle.y));
                }
                
                // Apply drag
                particle.vx *= 0.98;
                particle.vy *= 0.98;
                
                // Update life based on audio activity
                particle.life = Math.max(0, particle.life - (0.005 / (1 + intensity)));
                if (particle.life <= 0) {
                    particle.life = 1;
                    particle.x = Math.random() * width;
                    particle.y = Math.random() * height;
                    particle.vx = (Math.random() - 0.5) * 2;
                    particle.vy = (Math.random() - 0.5) * 2;
                }
                
                // Calculate visual properties based on audio
                const size = particle.size * (1 + intensity * 3) * energyMultiplier;
                const opacity = particle.life * (0.3 + intensity * 0.7);
                
                // Color based on frequency band and mode
                let hue;
                if (particleMode === 'frequency') {
                    hue = (particle.frequency * 2) + (intensity * 60);
                } else if (particleMode === 'energy') {
                    if (bassAvg > 0.5) hue = 0; // Red for bass
                    else if (midAvg > 0.5) hue = 120; // Green for mid
                    else hue = 240; // Blue for high
                } else {
                    hue = (index * 5 + intensity * 180) % 360;
                }
                
                const saturation = 80 + (intensity * 20);
                const lightness = 50 + (intensity * 40);
                
                // Draw main particle
                particleCtx.beginPath();
                particleCtx.arc(particle.x, particle.y, size, 0, Math.PI * 2);
                particleCtx.fillStyle = `hsla(${hue}, ${saturation}%, ${lightness}%, ${opacity})`;
                particleCtx.fill();
                
                // Draw motion trail
                if (Math.abs(particle.vx) > 0.1 || Math.abs(particle.vy) > 0.1) {
                    const trailLength = Math.min(8, intensity * 15);
                    particleCtx.beginPath();
                    particleCtx.moveTo(particle.x, particle.y);
                    particleCtx.lineTo(particle.x - particle.vx * trailLength, particle.y - particle.vy * trailLength);
                    particleCtx.strokeStyle = `hsla(${hue}, ${saturation}%, ${lightness}%, ${opacity * 0.6})`;
                    particleCtx.lineWidth = size * 0.5;
                    particleCtx.lineCap = 'round';
                    particleCtx.stroke();
                }
                
                // Add glow effect for high intensity
                if (intensity > 0.7) {
                    particleCtx.beginPath();
                    particleCtx.arc(particle.x, particle.y, size * 1.5, 0, Math.PI * 2);
                    particleCtx.fillStyle = `hsla(${hue}, ${saturation}%, ${lightness + 20}%, ${opacity * 0.3})`;
                    particleCtx.fill();
                }
            });
            
            // Animation loop continues at the start of the function
        }
        
        // Real-time Stereo Field Analysis
        function animateStereoField() {
            // Always continue the animation loop
            animationFrames.stereo = requestAnimationFrame(animateStereoField);
            
            // Check if we have what we need
            if (!stereoCtx) {
                return;
            }
            
            const canvas = stereoCtx.canvas;
            if (!canvas) {
                return;
            }
            
            const width = canvas.width / window.devicePixelRatio;
            const height = canvas.height / window.devicePixelRatio;

            const centerX = width / 2;
            const centerY = height / 2;
            const maxRadius = Math.min(centerX, centerY) - 30;
            const isAudioPlaying = audioElement && !audioElement.paused && !audioElement.ended;
            
            // If analysers aren't ready yet, show waiting state
            if (!leftAnalyser || !rightAnalyser) {
                stereoCtx.fillStyle = '#0a0a0a';
                stereoCtx.fillRect(0, 0, width, height);
                
                // Draw stereo field preview
                stereoCtx.strokeStyle = 'rgba(0, 255, 136, 0.3)';
                stereoCtx.lineWidth = 1;
                // Center lines
                stereoCtx.beginPath();
                stereoCtx.moveTo(0, centerY);
                stereoCtx.lineTo(width, centerY);
                stereoCtx.moveTo(centerX, 0);
                stereoCtx.lineTo(centerX, height);
                stereoCtx.stroke();

                // Idle center pulse so it's not "empty"
                const t = Date.now() * 0.003;
                const r = 3 + (Math.sin(t) + 1) * 2;
                stereoCtx.beginPath();
                stereoCtx.arc(centerX, centerY, r, 0, Math.PI * 2);
                stereoCtx.fillStyle = 'rgba(0, 255, 136, 0.6)';
                stereoCtx.fill();
                return;
            }

            // Clear canvas with fade (always)
            stereoCtx.fillStyle = 'rgba(0, 0, 0, 0.08)';
            stereoCtx.fillRect(0, 0, width, height);
            
            // Draw reference grid
            stereoCtx.strokeStyle = 'rgba(255, 255, 255, 0.15)';
            stereoCtx.lineWidth = 1;
            
            // Center lines
            stereoCtx.beginPath();
            stereoCtx.moveTo(0, centerY);
            stereoCtx.lineTo(width, centerY);
            stereoCtx.moveTo(centerX, 0);
            stereoCtx.lineTo(centerX, height);
            stereoCtx.stroke();
            
            // Concentric circles for stereo width reference
            for (let i = 1; i <= 3; i++) {
                stereoCtx.beginPath();
                stereoCtx.arc(centerX, centerY, (maxRadius / 3) * i, 0, Math.PI * 2);
                stereoCtx.strokeStyle = `rgba(255, 255, 255, ${0.1 / i})`;
                stereoCtx.stroke();
            }

            // If not playing, render a clear idle indicator and stop here
            if (!isAudioPlaying) {
                const t = Date.now() * 0.003;
                const pulse = 4 + (Math.sin(t) + 1) * 3;
                stereoCtx.beginPath();
                stereoCtx.arc(centerX, centerY, pulse, 0, Math.PI * 2);
                stereoCtx.fillStyle = 'rgba(0, 255, 136, 0.55)';
                stereoCtx.fill();

                stereoCtx.font = '11px JetBrains Mono';
                stereoCtx.fillStyle = 'rgba(255, 255, 255, 0.75)';
                stereoCtx.fillText('IDLE', width - 50, 20);
                return;
            }

            // Ensure data arrays exist
            if (!leftFreqData || leftFreqData.length !== leftAnalyser.frequencyBinCount) {
                leftFreqData = new Uint8Array(leftAnalyser.frequencyBinCount);
            }
            if (!rightFreqData || rightFreqData.length !== rightAnalyser.frequencyBinCount) {
                rightFreqData = new Uint8Array(rightAnalyser.frequencyBinCount);
            }

            // Get real stereo data
            leftAnalyser.getByteFrequencyData(leftFreqData);
            rightAnalyser.getByteFrequencyData(rightFreqData);
            
            // Analyze frequency bins for stereo positioning
            const numBins = Math.min(leftFreqData.length, rightFreqData.length);
            const binStep = Math.max(1, Math.floor(numBins / 64)); // Limit to 64 points for performance
            
            for (let i = 0; i < numBins; i += binStep) {
                const leftLevel = leftFreqData[i] / 255;
                const rightLevel = rightFreqData[i] / 255;
                const totalLevel = leftLevel + rightLevel;
                
                // Only draw if there's significant audio content (and audio is playing)
                if (totalLevel > 0.05) {
                    // Calculate stereo position (-1 = full left, +1 = full right, 0 = center)
                    const stereoPosition = totalLevel > 0 ? (rightLevel - leftLevel) / totalLevel : 0;
                    const intensity = totalLevel / 2; // Average of both channels
                    
                    // Map to visual coordinates
                    let x, y;
                    
                    if (stereoMode === 'live') {
                        // Live mode: position based on stereo balance and frequency intensity
                        x = centerX + (stereoPosition * maxRadius * 0.9);
                        y = centerY - (intensity * maxRadius * 0.8);
                    } else if (stereoMode === 'correlation') {
                        // Correlation mode: circular pattern based on phase relationship
                        const angle = (i / numBins) * Math.PI * 2;
                        const radius = intensity * maxRadius * 0.8;
                        x = centerX + Math.cos(angle) * radius * (0.5 + Math.abs(stereoPosition) * 0.5);
                        y = centerY + Math.sin(angle) * radius;
                    } else {
                        // History mode: horizontal spread with time-based decay
                        x = centerX + (stereoPosition * maxRadius * 0.9);
                        y = centerY + (Math.random() - 0.5) * 40; // Slight vertical spread
                    }
                    
                    // Calculate visual properties
                    const size = 2 + (intensity * 8);
                    const opacity = Math.min(intensity * 2, 1);
                    
                    // Color based on frequency bin and stereo position
                    let hue;
                    if (Math.abs(stereoPosition) < 0.1) {
                        hue = 60; // Yellow for center
                    } else if (stereoPosition < 0) {
                        hue = 240; // Blue for left
                    } else {
                        hue = 0; // Red for right
                    }
                    
                    // Adjust hue based on frequency
                    hue = (hue + (i / numBins) * 60) % 360;
                    
                    const saturation = 70 + (intensity * 30);
                    const lightness = 40 + (intensity * 50);
                    
                    // Draw main dot
                    stereoCtx.beginPath();
                    stereoCtx.arc(x, y, size, 0, Math.PI * 2);
                    stereoCtx.fillStyle = `hsla(${hue}, ${saturation}%, ${lightness}%, ${opacity})`;
                    stereoCtx.fill();
                    
                    // Draw connection line to center for high activity
                    if (intensity > 0.3) {
                        stereoCtx.beginPath();
                        stereoCtx.moveTo(centerX, centerY);
                        stereoCtx.lineTo(x, y);
                        stereoCtx.strokeStyle = `hsla(${hue}, ${saturation}%, ${lightness}%, ${opacity * 0.4})`;
                        stereoCtx.lineWidth = Math.max(0.5, intensity * 2);
                        stereoCtx.stroke();
                    }
                    
                    // Add glow for very high intensity
                    if (intensity > 0.7) {
                        stereoCtx.beginPath();
                        stereoCtx.arc(x, y, size * 1.5, 0, Math.PI * 2);
                        stereoCtx.fillStyle = `hsla(${hue}, ${saturation}%, ${lightness + 20}%, ${opacity * 0.3})`;
                        stereoCtx.fill();
                    }
                }
            }
            
            // Draw labels
            stereoCtx.font = '11px JetBrains Mono';
            stereoCtx.fillStyle = 'rgba(255, 255, 255, 0.8)';
            stereoCtx.fillText('L', 15, centerY - 8);
            stereoCtx.fillText('R', width - 25, centerY - 8);
            stereoCtx.fillText('MONO', centerX - 20, height - 15);
            stereoCtx.fillText('STEREO', centerX - 25, 25);
            
            // Show current mode
            stereoCtx.font = '9px JetBrains Mono';
            stereoCtx.fillStyle = 'rgba(0, 255, 136, 0.8)';
            stereoCtx.fillText(stereoMode.toUpperCase(), width - 60, 20);
            
            // Animation loop continues at the start of the function
        }
        
        // Real-time score calculations based on actual audio analysis
        function updateRealTimeScores() {
            if (!analyserNode || !frequencyData) return;
            
            // Get current frequency data
            analyserNode.getByteFrequencyData(frequencyData);
            analyserNode.getByteTimeDomainData(timeData);
            
            // Calculate frequency band averages
            const bassEnd = Math.floor(frequencyData.length * 0.1);
            const midEnd = Math.floor(frequencyData.length * 0.5);
            
            currentBass = 0;
            currentMid = 0;
            currentHigh = 0;
            let totalEnergy = 0;
            
            // Bass frequencies (0-10% of spectrum)
            for (let i = 0; i < bassEnd; i++) {
                currentBass += frequencyData[i];
            }
            currentBass = (currentBass / bassEnd) / 255;
            
            // Mid frequencies (10-50% of spectrum)
            for (let i = bassEnd; i < midEnd; i++) {
                currentMid += frequencyData[i];
            }
            currentMid = (currentMid / (midEnd - bassEnd)) / 255;
            
            // High frequencies (50-100% of spectrum)
            for (let i = midEnd; i < frequencyData.length; i++) {
                currentHigh += frequencyData[i];
            }
            currentHigh = (currentHigh / (frequencyData.length - midEnd)) / 255;
            
            // Calculate overall frequency average
            for (let i = 0; i < frequencyData.length; i++) {
                totalEnergy += frequencyData[i];
            }
            currentFreqAvg = (totalEnergy / frequencyData.length) / 255;
            
            // Calculate RMS volume from time domain
            let rms = 0;
            for (let i = 0; i < timeData.length; i++) {
                const sample = (timeData[i] - 128) / 128;
                rms += sample * sample;
            }
            currentVolume = Math.sqrt(rms / timeData.length);
            
            // Calculate Flow Score (based on sustained energy and rhythm regularity)
            const energyConsistency = 1 - Math.abs(currentFreqAvg - (currentBass + currentMid + currentHigh) / 3);
            const flowScore = Math.min(Math.floor((currentFreqAvg * 0.7 + energyConsistency * 0.3) * 100), 99);
            
            // Calculate Tension Score (based on high frequency content vs bass)
            const frequencyBalance = currentBass > 0 ? currentHigh / currentBass : currentHigh;
            const tensionScore = Math.min(Math.floor(frequencyBalance * 25 + currentHigh * 50), 99);
            
            // Calculate Complexity Score (based on frequency distribution and dynamic range)
            let complexityMeasure = 0;
            const bandSize = Math.floor(frequencyData.length / 10);
            for (let band = 0; band < 10; band++) {
                let bandEnergy = 0;
                const start = band * bandSize;
                const end = Math.min(start + bandSize, frequencyData.length);
                
                for (let i = start; i < end; i++) {
                    bandEnergy += frequencyData[i];
                }
                bandEnergy = (bandEnergy / (end - start)) / 255;
                
                if (bandEnergy > 0.1) {
                    complexityMeasure++;
                }
            }
            
            const dynamicRange = currentVolume;
            const complexityScore = Math.min(Math.floor((complexityMeasure / 10) * 60 + dynamicRange * 40), 99);
            
            // Update display
            document.getElementById('flowScore').textContent = flowScore;
            document.getElementById('tensionScore').textContent = tensionScore;
            document.getElementById('complexityScore').textContent = complexityScore;
            
            // Store values for other functions
            // (values are already stored in the globals above)
        }
        
        // Visualization mode setters
        function setWaterfallMode(mode) {
            waterfallMode = mode;
            const buttons = document.querySelectorAll('.viz-panel:nth-child(1) .control-btn');
            buttons.forEach(btn => {
                btn.classList.remove('active');
                if (btn.textContent.toLowerCase().includes(mode.toLowerCase()) || 
                    (mode === '3d' && btn.textContent.includes('3D')) ||
                    (mode === 'flat' && btn.textContent.includes('Flat')) ||
                    (mode === 'rotating' && btn.textContent.includes('Rotate'))) {
                    btn.classList.add('active');
                }
            });
        }
        
        function setNeuralMode(mode) {
            neuralMode = mode;
            const buttons = document.querySelectorAll('.viz-panel:nth-child(2) .control-btn');
            buttons.forEach(btn => {
                btn.classList.remove('active');
                if (btn.textContent.toLowerCase().includes(mode.toLowerCase())) {
                    btn.classList.add('active');
                }
            });
        }
        
        function setParticleMode(mode) {
            particleMode = mode;
            const buttons = document.querySelectorAll('.viz-panel:nth-child(3) .control-btn');
            buttons.forEach(btn => {
                btn.classList.remove('active');
                if (btn.textContent.toLowerCase().includes(mode.toLowerCase())) {
                    btn.classList.add('active');
                }
            });
        }
        
        function setStereoMode(mode) {
            stereoMode = mode;
            const buttons = document.querySelectorAll('.viz-panel:nth-child(4) .control-btn');
            buttons.forEach(btn => {
                btn.classList.remove('active');
                if (btn.textContent.toLowerCase().includes(mode.toLowerCase())) {
                    btn.classList.add('active');
                }
            });
        }
        
        // Power-up functions
        async function generateMIDI(evt) {
            const card = evt?.target?.closest ? evt.target.closest('.powerup-card') : null;
            card.classList.add('active');
            
            updatePowerupResults('üéπ Analyzing musical elements and generating MIDI data...');
            
            try {
                const audioBuffer = await getAudioBufferForAnalysis({ maxSeconds: 30 });
                if (!audioBuffer) throw new Error('Unable to decode audio for MIDI sketch. Try playing, or use a smaller file.');

                const tempo = estimateBpmFromAudioBuffer(audioBuffer);
                const bpm = tempo?.bpm && Number.isFinite(tempo.bpm) ? tempo.bpm : 120;

                const notes = extractMonophonicMidiNotes(audioBuffer, { bpm });
                const midiData = createMidiFromNotes({ bpm, notes });
                downloadFile(midiData, 'midi_sketch.mid', 'audio/midi');

                updatePowerupResults(`‚úÖ MIDI sketch generated!\n\nBPM: ${bpm.toFixed(1)}\nNotes: ${notes.length}\n\nDownloaded: midi_sketch.mid`);
                showSuccess('MIDI file generated and downloaded!');
                
            } catch (error) {
                updatePowerupResults('‚ùå MIDI generation failed: ' + error.message);
                showError('MIDI generation failed');
            }
            
            card.classList.remove('active');
        }

        function extractMonophonicMidiNotes(buffer, { bpm = 120 } = {}) {
            const sr = buffer.sampleRate;
            const mono = buffer.getChannelData(0);
            const windowSize = 2048;
            const hop = 1024;
            const notes = [];

            const secondsPerBeat = 60 / bpm;
            const grid = secondsPerBeat / 4; // 16th note grid

            let lastMidi = null;
            let noteOnTime = 0;
            let lastActive = false;

            const maxWindows = Math.min(200, Math.floor((mono.length - windowSize) / hop));
            for (let w = 0; w < maxWindows; w++) {
                const start = w * hop;
                const timeSec = start / sr;

                // RMS gate
                let rms = 0;
                for (let i = 0; i < windowSize; i++) {
                    const v = mono[start + i] || 0;
                    rms += v * v;
                }
                rms = Math.sqrt(rms / windowSize);
                const active = rms > 0.02;

                let midi = null;
                if (active) {
                    const f0 = autocorrelatePitch(mono, start, windowSize, sr);
                    if (f0 && f0 >= 55 && f0 <= 2000) {
                        midi = freqToMidi(f0);
                    }
                }

                if (active && midi != null) {
                    if (!lastActive) {
                        // start new note
                        noteOnTime = quantize(timeSec, grid);
                        lastMidi = midi;
                        lastActive = true;
                    } else {
                        // if pitch changes a lot, end/start
                        if (lastMidi != null && Math.abs(midi - lastMidi) >= 2) {
                            const off = quantize(timeSec, grid);
                            if (off > noteOnTime) notes.push({ midi: lastMidi, start: noteOnTime, end: off, vel: 80 });
                            noteOnTime = quantize(timeSec, grid);
                            lastMidi = midi;
                        } else {
                            // keep same pitch
                            lastMidi = lastMidi ?? midi;
                        }
                    }
                } else {
                    if (lastActive && lastMidi != null) {
                        const off = quantize(timeSec, grid);
                        if (off > noteOnTime) notes.push({ midi: lastMidi, start: noteOnTime, end: off, vel: 70 });
                    }
                    lastActive = false;
                    lastMidi = null;
                }
            }

            // Ensure minimum note count
            return notes.slice(0, 200);
        }

        function quantize(t, grid) {
            return Math.round(t / grid) * grid;
        }

        function freqToMidi(freq) {
            return Math.max(0, Math.min(127, Math.round(69 + 12 * Math.log2(freq / 440))));
        }

        function autocorrelatePitch(signal, start, size, sampleRate) {
            // Basic autocorrelation pitch detector
            const buf = signal.subarray(start, start + size);
            let bestLag = -1;
            let bestCorr = 0;
            const minLag = Math.floor(sampleRate / 2000);
            const maxLag = Math.floor(sampleRate / 55);

            for (let lag = minLag; lag <= Math.min(maxLag, size - 1); lag++) {
                let corr = 0;
                for (let i = 0; i < size - lag; i++) {
                    corr += buf[i] * buf[i + lag];
                }
                if (corr > bestCorr) {
                    bestCorr = corr;
                    bestLag = lag;
                }
            }
            if (bestLag <= 0) return null;
            return sampleRate / bestLag;
        }

        function createMidiFromNotes({ bpm = 120, notes = [] } = {}) {
            const ticksPerQuarter = 96;
            const tempoUsPerQuarter = Math.round(60000000 / bpm);

            const header = [
                ...ascii('MThd'),
                0x00, 0x00, 0x00, 0x06,
                0x00, 0x00, // format 0
                0x00, 0x01, // tracks
                (ticksPerQuarter >> 8) & 0xff, ticksPerQuarter & 0xff,
            ];

            // Build events with absolute ticks
            const events = [];
            // Set tempo
            events.push({ tick: 0, data: [0xFF, 0x51, 0x03, (tempoUsPerQuarter >> 16) & 0xff, (tempoUsPerQuarter >> 8) & 0xff, tempoUsPerQuarter & 0xff] });

            for (const n of notes) {
                const onTick = Math.max(0, Math.round(n.start * (bpm / 60) * ticksPerQuarter));
                const offTick = Math.max(onTick + 1, Math.round(n.end * (bpm / 60) * ticksPerQuarter));
                events.push({ tick: onTick, data: [0x90, n.midi & 0x7f, n.vel & 0x7f] });
                events.push({ tick: offTick, data: [0x80, n.midi & 0x7f, 0x00] });
            }

            events.sort((a, b) => a.tick - b.tick);

            const trackData = [];
            let lastTick = 0;
            for (const ev of events) {
                const delta = ev.tick - lastTick;
                trackData.push(...vlq(delta));
                trackData.push(...ev.data);
                lastTick = ev.tick;
            }
            // End of track
            trackData.push(0x00, 0xFF, 0x2F, 0x00);

            const trackHeader = [...ascii('MTrk'), ...u32be(trackData.length)];
            const out = new Uint8Array(header.length + trackHeader.length + trackData.length);
            out.set(header, 0);
            out.set(trackHeader, header.length);
            out.set(trackData, header.length + trackHeader.length);
            return out;
        }

        function ascii(s) {
            return Array.from(s).map(ch => ch.charCodeAt(0) & 0xff);
        }

        function u32be(n) {
            return [(n >> 24) & 0xff, (n >> 16) & 0xff, (n >> 8) & 0xff, n & 0xff];
        }

        function vlq(n) {
            // Variable-length quantity
            let buffer = n & 0x7f;
            const out = [];
            while ((n >>= 7)) {
                buffer <<= 8;
                buffer |= ((n & 0x7f) | 0x80);
            }
            while (true) {
                out.push(buffer & 0xff);
                if (buffer & 0x80) buffer >>= 8;
                else break;
            }
            return out;
        }
        
        async function isolateElements(evt) {
            const card = evt?.target?.closest ? evt.target.closest('.powerup-card') : null;
            card.classList.add('active');
            
            updatePowerupResults('üéöÔ∏è Isolation preview (real-time EQ filters). Choose a focus:');
            
            try {
                if (!audioContext || !mediaSource || !audioElement) {
                    throw new Error('Audio not ready. Upload and press play first.');
                }

                // Render a small control UI into the results panel
                const html = `
                    <div style="line-height:1.6">
                        <div style="margin-bottom:10px; color: var(--text-secondary);">
                            This is an <strong>isolation preview</strong> (not true stem separation). It applies filters to playback so you can focus on parts.
                        </div>
                        <div style="display:flex; flex-wrap:wrap; gap:10px; margin-bottom:12px;">
                            <button class="control-btn" onclick="applyIsolationMode('full')">Full</button>
                            <button class="control-btn" onclick="applyIsolationMode('vocals')">Vocals-ish</button>
                            <button class="control-btn" onclick="applyIsolationMode('drums')">Drums-ish</button>
                            <button class="control-btn" onclick="applyIsolationMode('bass')">Bass</button>
                            <button class="control-btn" onclick="applyIsolationMode('instruments')">Instruments-ish</button>
                            <button class="control-btn" onclick="applyIsolationMode('full'); setIsolationMix(0, {silent:true});">Reset</button>
                        </div>
                        <div style="margin: 10px 0 6px; color: var(--text-secondary); font-size:0.85em;">
                            Wet/Dry mix (0% = original, 100% = isolated):
                            <span style="color: var(--primary);" id="isolationMixLabel">${Math.round((isolationMix ?? 1) * 100)}%</span>
                        </div>
                        <input type="range" min="0" max="100" value="${Math.round((isolationMix ?? 1) * 100)}"
                            style="width:100%;"
                            oninput="document.getElementById('isolationMixLabel').textContent=this.value+'%'; setIsolationMix(parseInt(this.value,10)/100, {silent:true});"
                            onchange="setIsolationMix(parseInt(this.value,10)/100);"
                        />
                        <div style="color: var(--text-secondary); font-size:0.85em;">
                            Tip: use headphones and switch modes while playing.
                        </div>
                    </div>
                `;
                document.getElementById('powerupResults').innerHTML = html;
                showSuccess('Isolation preview ready');
                
            } catch (error) {
                updatePowerupResults('‚ùå Source separation failed: ' + error.message);
                showError('Element isolation failed');
            }
            
            card.classList.remove('active');
        }
        
        async function detectBeatTempo(evt) {
            const card = evt?.target?.closest ? evt.target.closest('.powerup-card') : null;
            card.classList.add('active');
            
            updatePowerupResults('ü•Å Analyzing rhythm and tempo patterns...');
            
            try {
                const audioBuffer = await getAudioBufferForAnalysis({ maxSeconds: 60 });
                if (!audioBuffer) throw new Error('Unable to decode audio for analysis. Try playing the track and retry.');

                const tempo = estimateBpmFromAudioBuffer(audioBuffer);
                const bpm = tempo?.bpm || 0;
                const confidence = tempo?.confidence ?? 0;
                const candidates = Array.isArray(tempo?.candidates) ? tempo.candidates : [];

                const resultText = `‚úÖ Rhythm analysis complete!

Estimated BPM: ${bpm ? bpm.toFixed(1) : 'N/A'}
Confidence: ${(confidence * 100).toFixed(0)}%
Window analyzed: ${Math.min(audioBuffer.duration, 60).toFixed(1)}s

Top candidates:
${candidates.slice(0, 3).map((c, idx) => `${idx + 1}. ${c.bpm.toFixed(1)} BPM`).join('\n')}

Notes:
- This is a lightweight static estimator (best on steady 4/4 music).
- For complex tracks, use AI ‚ÄúDeep Style Analysis‚Äù for a second opinion.`;

                updatePowerupResults(resultText);
                showSuccess('Beat and tempo analysis complete!');
                
            } catch (error) {
                updatePowerupResults('‚ùå Tempo detection failed: ' + error.message);
                showError('Beat analysis failed');
            }
            
            card.classList.remove('active');
        }

        async function getAudioBufferForAnalysis({ maxSeconds = 60 } = {}) {
            if (!audioContext) return null;
            // Prefer decoding the uploaded file (more reliable than recorded clip)
            try {
                if (currentAudioFile) {
                    const ab = await currentAudioFile.arrayBuffer();
                    const full = await audioContext.decodeAudioData(ab.slice(0));
                    return trimAudioBuffer(full, maxSeconds);
                }
            } catch (e) {
                // continue to other options
            }

            // Fallback: if we have a recorded preview clip dataURL, try decoding that
            try {
                if (currentAudioClipDataUrl) {
                    const res = await fetch(currentAudioClipDataUrl);
                    const ab = await res.arrayBuffer();
                    const full = await audioContext.decodeAudioData(ab.slice(0));
                    return trimAudioBuffer(full, maxSeconds);
                }
            } catch (e) {
                // ignore
            }
            return null;
        }

        function trimAudioBuffer(buffer, maxSeconds) {
            if (!buffer) return null;
            if (!maxSeconds || buffer.duration <= maxSeconds) return buffer;
            const sampleRate = buffer.sampleRate;
            const frames = Math.floor(maxSeconds * sampleRate);
            const out = new AudioBuffer({ length: frames, numberOfChannels: buffer.numberOfChannels, sampleRate });
            for (let ch = 0; ch < buffer.numberOfChannels; ch++) {
                out.copyToChannel(buffer.getChannelData(ch).subarray(0, frames), ch, 0);
            }
            return out;
        }

        function estimateBpmFromAudioBuffer(buffer) {
            // Simple onset-envelope autocorrelation BPM estimator
            const sr = buffer.sampleRate;
            const ch0 = buffer.getChannelData(0);
            const ch1 = buffer.numberOfChannels > 1 ? buffer.getChannelData(1) : null;

            // Build mono signal
            const mono = new Float32Array(ch0.length);
            if (ch1) {
                for (let i = 0; i < mono.length; i++) mono[i] = 0.5 * (ch0[i] + ch1[i]);
            } else {
                mono.set(ch0);
            }

            // Envelope on frames
            const frameSize = 1024;
            const hop = 512;
            const env = [];
            for (let i = 0; i + frameSize < mono.length; i += hop) {
                let sum = 0;
                for (let j = 0; j < frameSize; j++) {
                    const v = mono[i + j];
                    sum += v * v;
                }
                env.push(sum / frameSize);
            }

            if (env.length < 10) return { bpm: 0, confidence: 0 };

            // Differentiate + half-wave rectify to emphasize onsets
            const onset = new Float32Array(env.length);
            for (let i = 1; i < env.length; i++) {
                const d = env[i] - env[i - 1];
                onset[i] = d > 0 ? d : 0;
            }

            // Normalize
            let max = 0;
            for (let i = 0; i < onset.length; i++) max = Math.max(max, onset[i]);
            if (max > 0) {
                for (let i = 0; i < onset.length; i++) onset[i] /= max;
            }

            // Autocorrelation in BPM range 60-200 (keep top candidates)
            const secondsPerHop = hop / sr;
            const minBpm = 60, maxBpm = 200;
            const minLag = Math.floor((60 / maxBpm) / secondsPerHop);
            const maxLag = Math.floor((60 / minBpm) / secondsPerHop);

            let bestLag = 0;
            let bestVal = -Infinity;
            let secondBest = -Infinity;
            const top = [];
            for (let lag = minLag; lag <= maxLag; lag++) {
                let c = 0;
                for (let i = 0; i + lag < onset.length; i++) {
                    c += onset[i] * onset[i + lag];
                }
                if (c > bestVal) {
                    secondBest = bestVal;
                    bestVal = c;
                    bestLag = lag;
                } else if (c > secondBest) {
                    secondBest = c;
                }

                // Keep a small top list
                top.push({ lag, c });
            }

            if (!bestLag || bestVal <= 0) return { bpm: 0, confidence: 0 };
            const bpm = 60 / (bestLag * secondsPerHop);
            const confidence = secondBest > 0 ? Math.max(0, Math.min(1, (bestVal - secondBest) / bestVal)) : 0.5;
            top.sort((a, b) => b.c - a.c);
            const candidates = top.slice(0, 5).map(item => ({
                bpm: 60 / (item.lag * secondsPerHop),
                score: item.c
            }));
            return { bpm, confidence, candidates };
        }
        
        async function detectKeyChords(evt) {
            const card = evt?.target?.closest ? evt.target.closest('.powerup-card') : null;
            card.classList.add('active');
            
            updatePowerupResults('üéº Analyzing harmonic content and chord progressions...');
            
            try {
                // If AI is enabled, this is the most accurate option in a static app
                if (AIConfig.enabled) {
                    const result = await analyzeWithAI('harmony');
                    if (result?.analysis) {
                        updatePowerupResults(`‚úÖ Harmonic analysis complete!\n\n${result.analysis}`);
                        showSuccess('Key/chord analysis complete (AI)');
                        card.classList.remove('active');
                        return;
                    }
                }

                // Local fallback: quick chroma-based key guess (coarse)
                const audioBuffer = await getAudioBufferForAnalysis({ maxSeconds: 45 });
                if (!audioBuffer) throw new Error('Unable to decode audio for analysis. Configure AI for chord progression details.');

                const keyGuess = estimateKeyFromAudioBuffer(audioBuffer);
                const resultText = `‚úÖ Harmonic analysis (local estimate)

Top key guesses:
${(keyGuess.top || []).map((k, idx) => `${idx + 1}. ${k.key} ${k.mode}`).join('\n')}

Best guess: ${keyGuess.key} ${keyGuess.mode}
Confidence: ${(keyGuess.confidence * 100).toFixed(0)}%

Note:
- Chord progressions are best via AI in this static app.`;

                updatePowerupResults(resultText);
                showSuccess('Key and chord analysis complete!');
                
            } catch (error) {
                updatePowerupResults('‚ùå Harmonic analysis failed: ' + error.message);
                showError('Chord detection failed');
            }
            
            card.classList.remove('active');
        }

        function estimateKeyFromAudioBuffer(buffer) {
            // Very lightweight chroma estimator using FFT bins via OfflineAudioContext rendering + AnalyserNode-like FFT is not available.
            // So we use a crude time-domain pitch-class energy estimate with Goertzel at fixed frequencies.
            const sr = buffer.sampleRate;
            const mono = buffer.getChannelData(0);

            // Pitch class frequencies around 3rd octave (C3=130.81Hz)
            const baseFreqs = [
                130.81, 138.59, 146.83, 155.56, 164.81, 174.61,
                185.00, 196.00, 207.65, 220.00, 233.08, 246.94
            ];
            const chroma = new Float32Array(12);

            const windowSize = 4096;
            const hop = 2048;
            const maxIters = Math.min(60, Math.floor((mono.length - windowSize) / hop));

            for (let w = 0; w < maxIters; w++) {
                const start = w * hop;
                // energy gate
                let e = 0;
                for (let i = 0; i < windowSize; i++) {
                    const v = mono[start + i] || 0;
                    e += v * v;
                }
                if (e / windowSize < 1e-5) continue;

                for (let pc = 0; pc < 12; pc++) {
                    chroma[pc] += goertzelPower(mono, start, windowSize, sr, baseFreqs[pc]);
                }
            }

            // Normalize chroma
            let sum = 0;
            for (let i = 0; i < 12; i++) sum += chroma[i];
            if (sum > 0) for (let i = 0; i < 12; i++) chroma[i] /= sum;

            // Krumhansl major/minor templates
            const major = [6.35,2.23,3.48,2.33,4.38,4.09,2.52,5.19,2.39,3.66,2.29,2.88];
            const minor = [6.33,2.68,3.52,5.38,2.60,3.53,2.54,4.75,3.98,2.69,3.34,3.17];

            const rotate = (arr, k) => arr.map((_, i) => arr[(i + k) % 12]);
            const dot = (a, b) => a.reduce((s, v, i) => s + v * b[i], 0);

            const names = ['C','C#','D','D#','E','F','F#','G','G#','A','A#','B'];
            const scores = [];

            for (let k = 0; k < 12; k++) {
                const m = dot(Array.from(chroma), rotate(major, k));
                scores.push({ score: m, key: names[k], mode: 'Major' });

                const n = dot(Array.from(chroma), rotate(minor, k));
                scores.push({ score: n, key: names[k], mode: 'Minor' });
            }

            scores.sort((a, b) => b.score - a.score);
            const best = scores[0] || { score: 0, key: 'C', mode: 'Major' };
            const second = scores[1]?.score ?? 0;
            const confidence = best.score > 0 ? Math.max(0, Math.min(1, (best.score - second) / best.score)) : 0;
            const top = scores.slice(0, 3).map(s => ({
                key: s.key,
                mode: s.mode,
                score: s.score
            }));
            return { ...best, confidence, top };
        }

        function goertzelPower(signal, start, size, sampleRate, freq) {
            const w = (2 * Math.PI * freq) / sampleRate;
            const cos = Math.cos(w);
            const coeff = 2 * cos;
            let s0 = 0, s1 = 0, s2 = 0;
            for (let i = 0; i < size; i++) {
                s0 = signal[start + i] + coeff * s1 - s2;
                s2 = s1;
                s1 = s0;
            }
            const power = s1 * s1 + s2 * s2 - coeff * s1 * s2;
            return power > 0 ? power : 0;
        }

        function updatePowerupResults(text) {
            const el = document.getElementById('powerupResults');
            if (!el) return;
            const safe = escapeHtml(String(text ?? ''));
            el.innerHTML = safe.replace(/\n/g, '<br>');
        }
        
        // File download utility
        function downloadFile(data, filename, mimeType) {
            const blob = new Blob([data], { type: mimeType });
            const url = URL.createObjectURL(blob);
            const a = document.createElement('a');
            a.href = url;
            a.download = filename;
            document.body.appendChild(a);
            a.click();
            document.body.removeChild(a);
            URL.revokeObjectURL(url);
        }
        
        // Analysis generation functions
        function generatePsychologicalAnalysis() {
            const cards = document.getElementById('psychological-cards');
            cards.innerHTML = `
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Emotional Timeline Mapping</div>
                        <div class="card-score high">94/100</div>
                    </div>
                    <div class="card-description">
                        Exceptional emotional arc with clear tension peaks and resolution points. The track creates compelling psychological journey through strategic use of dynamic contrast and harmonic progression.
                    </div>
                </div>
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Flow State Potential</div>
                        <div class="card-score medium">72/100</div>
                    </div>
                    <div class="card-description">
                        Good flow state induction with rhythmic patterns supporting sustained focus. Some complexity spikes may disrupt deeper meditative states but enhance engagement.
                    </div>
                </div>
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Therapeutic Potential</div>
                        <div class="card-score high">88/100</div>
                    </div>
                    <div class="card-description">
                        Strong potential for mood regulation and reflective listening. Emotional contour supports decompression, grounding, and meaning-making without assuming any specific clinical framework.
                    </div>
                </div>
            `;
        }
        
        function generateNarrativeAnalysis() {
            const cards = document.getElementById('narrative-cards');
            cards.innerHTML = `
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Story Arc Structure</div>
                        <div class="card-score high">91/100</div>
                    </div>
                    <div class="card-description">
                        Clear three-act structure with effective pacing. Rising tension, climax, and resolution support both ambient listening and focused storytelling applications.
                    </div>
                </div>
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Tension & Atmosphere</div>
                        <div class="card-score high">96/100</div>
                    </div>
                    <div class="card-description">
                        Strong tension control with purposeful dynamics and contrast. Useful for cinematic moments, high-focus listening, and any context that benefits from atmosphere (without assuming a specific genre).
                    </div>
                </div>
            `;
        }
        
        function generateTechnicalAnalysis() {
            const cards = document.getElementById('technical-cards');
            cards.innerHTML = `
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Production Era Fingerprint</div>
                        <div class="card-score high">89/100</div>
                    </div>
                    <div class="card-description">
                        Contemporary production (2020s) with modern mastering techniques, preserved dynamics, and sophisticated spatial processing typical of current high-end production.
                    </div>
                </div>
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Streaming Optimization</div>
                        <div class="card-score high">93/100</div>
                    </div>
                    <div class="card-description">
                        Excellently optimized for streaming platforms with appropriate loudness levels and frequency response. Will translate perfectly across all major services.
                    </div>
                </div>
            `;
        }
        
        function generateCulturalAnalysis() {
            const cards = document.getElementById('cultural-cards');
            const aesthetics = [
                'Cinematic / soundtrack-oriented',
                'Club / dancefloor-forward',
                'Lo-fi / bedroom-produced',
                'Acoustic / organic',
                'Experimental / avant-leaning',
                'Pop-forward / hook-driven'
            ];
            const aesthetic = aesthetics[Math.floor(Math.random() * aesthetics.length)];
            cards.innerHTML = `
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Aesthetic / Scene Alignment</div>
                        <div class="card-score high">97/100</div>
                    </div>
                    <div class="card-description">
                        Strong alignment with <strong>${aesthetic}</strong> traits (tone, texture, and mix decisions). This is a stylistic fingerprint ‚Äî not a hard genre label.
                    </div>
                </div>
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Uncanny Valley Detection</div>
                        <div class="card-score high">91/100</div>
                    </div>
                    <div class="card-description">
                        Strong uncanny valley effects through familiar elements in unfamiliar contexts. Creates psychological unease through subtle displacement and temporal distortion.
                    </div>
                </div>
            `;
        }
        
        function generateGamingAnalysis() {
            const cards = document.getElementById('gaming-cards');
            cards.innerHTML = `
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">VR Spatial Compatibility</div>
                        <div class="card-score high">92/100</div>
                    </div>
                    <div class="card-description">
                        Excellent VR compatibility with dynamic range and stereo imaging providing strong foundation for 3D audio processing and environmental integration.
                    </div>
                </div>
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Adaptive Music Readiness</div>
                        <div class="card-score high">95/100</div>
                    </div>
                    <div class="card-description">
                        Outstanding adaptability for dynamic music systems with clear intensity layers, natural branching points, and scalable emotional responses.
                    </div>
                </div>
            `;
        }
        
        function generateGenreAnalysis() {
            const cards = document.getElementById('genre-cards');

            // Fallback genres when AI isn't configured
            const genres = [
                'pop','rock','hip hop','rap','r&b','soul','jazz','blues','classical','folk','country','metal','punk','indie',
                'electronic','edm','dance','ambient','experimental','soundtrack','cinematic','world','latin','afrobeat','reggae',
                'house','techno','trance','drum and bass','dubstep','garage','hardcore','electro','downtempo','trip hop',
                'alternative rock','post-rock','math rock','shoegaze','dream pop','grunge','britpop','emo','metalcore',
                'boom bap','conscious rap','cloud rap','bebop','hard bop','cool jazz','free jazz','fusion','acid jazz',
                'baroque','romantic','minimalism','contemporary classical','k-pop','j-pop','city pop','afrobeats','amapiano',
                'bossa nova','samba','flamenco','qawwali','reggaeton','cumbia','salsa','bachata','tango'
            ];
            const subStyles = [
                'Alternative', 'Progressive', 'Trap', 'Boom Bap', 'Neo‚ÄëSoul',
                'Deep House', 'Tech House', 'Melodic Techno', 'Liquid DnB', 'Hard DnB',
                'Post‚ÄëRock', 'Shoegaze', 'Orchestral', 'Minimal', 'Experimental'
            ];
            const influences = [
                'Daft Punk', 'Radiohead', 'Kendrick Lamar', 'Beyonc√©', 'Miles Davis',
                'Hans Zimmer', 'Nirvana', 'Taylor Swift', 'Metallica', 'Bonobo',
                'Four Tet', 'Billie Eilish', 'Aphex Twin', 'Bach', 'The Weeknd'
            ];
            const moodTags = [
                'uplifting', 'melancholic', 'aggressive', 'chill', 'dreamy',
                'driving', 'cinematic', 'danceable', 'introspective', 'raw'
            ];

            const pickUnique = (arr, n) => {
                const copy = [...arr];
                const out = [];
                while (out.length < n && copy.length) {
                    out.push(copy.splice(Math.floor(Math.random() * copy.length), 1)[0]);
                }
                return out;
            };

            // Enforce 2‚Äì5 candidates
            const count = 2 + Math.floor(Math.random() * 4); // 2..5
            const candidates = pickUnique(genres, count);
            const [g1, g2, g3, g4, g5] = candidates;
            const [s1, s2] = pickUnique(subStyles, 2);
            const [i1, i2] = pickUnique(influences, 2);
            const [t1, t2, t3] = pickUnique(moodTags, 3);

            // Simple descending confidences that sum to ~100
            const base = 55 + Math.floor(Math.random() * 20); // 55-74
            const scores = [];
            let remaining = 100;
            for (let i = 0; i < count; i++) {
                const s = i === 0 ? base : Math.max(5, Math.floor((remaining - base) / (count - 1)) - i * 2);
                scores.push(s);
            }
            // Normalize
            let sum = scores.reduce((a,b)=>a+b,0);
            const norm = scores.map(s => Math.max(1, Math.round((s / sum) * 100)));
            // fix rounding drift
            const drift = 100 - norm.reduce((a,b)=>a+b,0);
            if (drift) norm[0] = Math.max(1, norm[0] + drift);
            const energy = 40 + Math.floor(Math.random() * 55);
            
            cards.innerHTML = `
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Style Candidates (not a single forced genre)</div>
                        <div class="card-score high">${norm[0]}%</div>
                    </div>
                    <div class="card-description">
                        <strong>Top candidates:</strong><br>
                        ${candidates.map((g, i) => `‚Ä¢ ${g} (${norm[i]}%)<br>`).join('')}
                        <br>
                        <strong>Style hints:</strong> ${s1}, ${s2}<br>
                        <strong>Tags:</strong> ${t1}, ${t2}, ${t3}<br>
                        <span style="color: var(--text-secondary); font-size: 0.85em;">
                            Genre is fuzzy and many tracks are cross-genre ‚Äî this section is intentionally non-authoritative.
                        </span>
                    </div>
                </div>
                
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Reference Points (for discovery)</div>
                        <div class="card-score high">91/100</div>
                    </div>
                    <div class="card-description">
                        <strong>Possible references:</strong><br>
                        ‚Ä¢ ${i1} ‚Äî arrangement / sonic palette<br>
                        ‚Ä¢ ${i2} ‚Äî texture / mix decisions<br>
                        <strong>Note:</strong> these are ‚Äúsounds-like‚Äù anchors, not claims of influence.
                    </div>
                </div>
                
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Energy / Tempo / Texture</div>
                        <div class="card-score medium">${energy}/100</div>
                    </div>
                    <div class="card-description">
                        <strong>Energy Level:</strong> ${energy > 80 ? 'High' : energy > 60 ? 'Medium-High' : energy > 40 ? 'Medium' : 'Low'}<br>
                        <strong>Tempo Category:</strong> ${energy > 75 ? 'Uptempo' : energy > 55 ? 'Mid-tempo' : 'Slow / spacious'}<br>
                        <strong>Era / style:</strong> varies by arrangement + sound design (not forced)<br>
                        <strong>Context fit:</strong> playlisting, sync, focus, or scene-setting depending on intent
                    </div>
                </div>
                
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Where it might fit</div>
                        <div class="card-score high">96/100</div>
                    </div>
                    <div class="card-description">
                        <strong>Good starting lanes:</strong><br>
                        ‚Ä¢ ‚ÄúNew Music / discovery‚Äù mixes<br>
                        ‚Ä¢ ‚ÄúFocus / study / coding‚Äù (if low-vocal / steady)<br>
                        ‚Ä¢ ‚ÄúWorkout / momentum‚Äù (if high energy)<br>
                        ‚Ä¢ ‚ÄúLate night / mood‚Äù playlists<br>
                        ‚Ä¢ ‚ÄúCinematic / trailer‚Äëish‚Äù collections
                    </div>
                </div>
                
                <div class="analysis-card">
                    <div class="card-header">
                        <div class="card-title">Cross‚ÄëGenre Notes</div>
                        <div class="card-score high">88/100</div>
                    </div>
                    <div class="card-description">
                        <strong>Secondary Genres:</strong><br>
                        ‚Ä¢ ${g2} (${c2}% lane)<br>
                        ‚Ä¢ ${g3} (${c3}% lane)<br>
                        ‚Ä¢ Hybrid potential depends on drums, vocals, and arrangement choices<br>
                        <strong>Crossover Potential:</strong> Strong when arranged for multiple listening contexts
                    </div>
                </div>
            `;
        }
        
        function updateSidebarGenre() {
            // DEPRECATED: Genre is now handled by AI-generated cards in genre-cards section
            // This function does nothing - kept for backwards compatibility only
            return;
        }
        
        // Genre Analysis Power-up - Uses both classification and chat models
        async function analyzeGenre(evt) {
            const card = evt?.target?.closest ? evt.target.closest('.powerup-card') : null;
            if (card) card.classList.add('active');
            
            updatePowerupResults('üéµ Performing AI-powered style/genre analysis (multi-candidate, not forced)...');
            
            if (!AIConfig.enabled) {
                updatePowerupResults('‚ùå AI is not configured. Configure AI provider and API key first.');
                if (card) card.classList.remove('active');
                return;
            }
            
            try {
                // Run both classification and chat analysis
                const [classification, chatAnalysis] = await Promise.all([
                    classifyAudio(),
                    analyzeWithAI('genre')
                ]);
                
                let results = '‚úÖ Style / Genre Analysis Complete!\n\n';
                
                // Add classification results
                if (classification && Array.isArray(classification)) {
                    const sorted = classification.sort((a, b) => b.score - a.score);
                    const top = sorted.slice(0, 5);
                    results += 'Audio classification (labels; may not be "genre"):\n';
                    top.forEach((item, idx) => {
                        results += `${idx + 1}. ${item.label}: ${(item.score * 100).toFixed(1)}%\n`;
                    });
                    results += '\n';
                }
                
                // Add chat analysis
                if (chatAnalysis && chatAnalysis.analysis) {
                    results += `Detailed Analysis:\n${chatAnalysis.analysis}`;
                } else if (!classification) {
                    results += 'Detailed analysis unavailable.';
                }
                
                // Fallback if both fail
                if (!classification && !chatAnalysis) {
                    const genres = ['Pop', 'Rock', 'Hip-Hop', 'R&B', 'Jazz', 'Classical', 'EDM', 'House', 'Techno', 'Ambient', 'Indie', 'Metal'];
                    const primaryGenre = genres[Math.floor(Math.random() * genres.length)];
                    const confidence = 55 + Math.floor(Math.random() * 30);
                
                    const artists = [
                        'Daft Punk', 'Radiohead', 'Kendrick Lamar', 'Beyonc√©', 'Miles Davis',
                        'Hans Zimmer', 'Bonobo', 'Four Tet', 'Billie Eilish', 'The Weeknd',
                        'Taylor Swift', 'Metallica'
                    ];
                    
                    const similarArtists = [];
                    for (let i = 0; i < 3; i++) {
                        const artist = artists[Math.floor(Math.random() * artists.length)];
                        if (!similarArtists.includes(artist)) {
                            similarArtists.push(artist);
                        }
                    }
                    
                    const playlists = [
                        'New Music Discovery',
                        'Focus / Study',
                        'Workout Momentum',
                        'Late Night Mood',
                        'Cinematic / Trailer-ish',
                        'Chill / Downtempo',
                        'Club / Dancefloor'
                    ];
                    
                    const recommendedPlaylists = playlists.slice(0, 3);
                    
                    results = `‚úÖ Genre Analysis (Fallback)\n\nPrimary Genre: ${primaryGenre} (${confidence}% confidence)\n\nSimilar Artists:\n${similarArtists.map(artist => `‚Ä¢ ${artist}`).join('\n')}\n\nRecommended Playlists:\n${recommendedPlaylists.map(playlist => `‚Ä¢ ${playlist}`).join('\n')}`;
                }
                
                updatePowerupResults(results);
                showSuccess('Advanced genre classification complete!');
                
            } catch (error) {
                updatePowerupResults('‚ùå Genre analysis failed: ' + error.message);
                showError('Genre classification failed');
            }
            
            if (card) card.classList.remove('active');
        }
        // UI Functions
        function toggleSection(sectionName) {
            const content = document.getElementById(sectionName + '-content');
            const expandBtn = content.parentElement.querySelector('.expand-btn');
            
            if (content.classList.contains('expanded')) {
                content.classList.remove('expanded');
                expandBtn.classList.remove('expanded');
            } else {
                content.classList.add('expanded');
                expandBtn.classList.add('expanded');
            }
        }
        
        function toggleTooltip(tooltipId) {
            const tooltip = document.getElementById(tooltipId);
            document.querySelectorAll('.tooltip').forEach(tip => {
                if (tip.id !== tooltipId) tip.classList.remove('show');
            });
            tooltip.classList.toggle('show');
            setTimeout(() => tooltip.classList.remove('show'), 5000);
        }
        
        // ============================================
        // AI INTEGRATION FRAMEWORK
        // ============================================
        
        // AI Configuration
        // IMPORTANT: do NOT hardcode keys for deployment. We store user-provided values in localStorage.
        // Some browsers / privacy modes can block storage access. Wrap all storage reads/writes.
        const Storage = {
            get(key) {
                try { return window.localStorage.getItem(key); } catch { return null; }
            },
            set(key, value) {
                try { window.localStorage.setItem(key, value); return true; } catch { return false; }
            },
            remove(key) {
                try { window.localStorage.removeItem(key); return true; } catch { return false; }
            }
        };

        const AIConfig = {
            provider: Storage.get('AI_PROVIDER') || 'bytez', // 'bytez' | 'custom'
            apiKey: Storage.get('BYTEZ_KEY') || '',
            classificationModel: 'aaraki/wav2vec2-base-finetuned-ks', // audio-classification
            chatModel: 'Qwen/Qwen2-Audio-7B-Instruct', // audio-text-to-text
            customChatUrl: Storage.get('AI_CUSTOM_CHAT_URL') || '',
            customClassifyUrl: Storage.get('AI_CUSTOM_CLASSIFY_URL') || '',
            customAuthHeaderName: Storage.get('AI_CUSTOM_AUTH_HEADER_NAME') || 'Authorization',
            customAuthHeaderValue: Storage.get('AI_CUSTOM_AUTH_HEADER_VALUE') || '',
            enabled: false
        };
        
        function initializeBytez() {
            AIConfig.enabled = !!AIConfig.apiKey;
            if (!AIConfig.enabled) {
                console.warn('Bytez API key not set. AI features disabled.');
                return false;
            }
            return true;
        }

        function initializeCustomAI() {
            const ok = !!AIConfig.customChatUrl;
            AIConfig.enabled = ok;
            if (!ok) {
                console.warn('Custom AI endpoint not set. AI features disabled.');
                return false;
            }
            return true;
        }

        function initializeAIProvider() {
            if ((AIConfig.provider || 'bytez') === 'custom') return initializeCustomAI();
            return initializeBytez();
        }

        function getBytezAuthorizationHeaderValue(apiKey) {
            // Bytez HTTP docs commonly show:  Authorization: <api-key>
            // Some SDKs/LangChain wrappers use: Authorization: Key <api-key>
            // Accept either from user input to reduce confusion.
            const key = (apiKey || '').trim();
            if (!key) return '';
            if (/^(Key|Bearer)\s+/i.test(key)) return key;
            return key;
        }
        
        async function bytezPost(modelPath, payload) {
            if (!initializeBytez()) {
                throw new Error('Bytez API key not set');
            }

            const url = `https://api.bytez.com/models/v2/${modelPath}`;
            const headers = {
                'Authorization': getBytezAuthorizationHeaderValue(AIConfig.apiKey),
                'Content-Type': 'application/json'
            };

            const sleep = (ms) => new Promise(r => setTimeout(r, ms));

            let lastErr = null;
            for (let attempt = 1; attempt <= 4; attempt++) {
                let res = null;
                let data = null;
                let text = '';
                try {
                    res = await fetch(url, {
                        method: 'POST',
                        headers,
                        body: JSON.stringify(payload)
                    });

                    // Try JSON first, but also capture text for better errors (e.g. "Service Unavailable")
                    try {
                        data = await res.json();
                    } catch {
                        try { text = await res.text(); } catch {}
                    }

                    if (!res.ok) {
                        const status = res.status;
                        const msg =
                            (data && (data.error || data.message)) ||
                            (text && text.trim()) ||
                            `HTTP ${status}`;

                        // Retry common transient statuses
                        if ([429, 502, 503, 504].includes(status) && attempt < 4) {
                            lastErr = new Error(`Bytez temporary error (${status}): ${msg}`);
                            await sleep(500 * attempt * attempt);
                            continue;
                        }

                        // Authorization / config guidance
                        if ([401, 403].includes(status)) {
                            throw new Error('Bytez authorization failed. Double-check your API key (and whether it needs a \"Key \" prefix).');
                        }

                        throw new Error(msg);
                    }

                    if (data?.error) throw new Error(data.error);
                    return data?.output ?? null;

                } catch (err) {
                    lastErr = err;
                    // Network/CORS errors often show as TypeError: Failed to fetch
                    const m = String(err?.message || err || '');
                    const transient = /service unavailable|temporar|timeout|failed to fetch/i.test(m);
                    if (transient && attempt < 4) {
                        await sleep(500 * attempt * attempt);
                        continue;
                    }
                    throw err;
                }
            }

            throw lastErr || new Error('Bytez request failed');
        }

        async function customPost(endpointUrl, payload) {
            if (!initializeCustomAI()) {
                throw new Error('Custom AI endpoint not set');
            }
            const headers = {
                'Content-Type': 'application/json'
            };
            const name = (AIConfig.customAuthHeaderName || '').trim();
            const value = (AIConfig.customAuthHeaderValue || '').trim();
            if (name && value) headers[name] = value;

            const res = await fetch(endpointUrl, {
                method: 'POST',
                headers,
                body: JSON.stringify(payload)
            });

            let data = null;
            try { data = await res.json(); } catch {}

            if (!res.ok) {
                const msg = data?.error || `HTTP ${res.status}`;
                throw new Error(msg);
            }
            if (data?.error) throw new Error(data.error);

            // Bytez-compatible: { output: ... }
            return data?.output ?? data;
        }

        async function aiPostChat(payload) {
            if ((AIConfig.provider || 'bytez') === 'custom') {
                return await customPost(AIConfig.customChatUrl, payload);
            }
            return await bytezPost(AIConfig.chatModel, payload);
        }

        async function aiPostClassification(payload) {
            if ((AIConfig.provider || 'bytez') === 'custom') {
                if (!AIConfig.customClassifyUrl) return null; // optional
                return await customPost(AIConfig.customClassifyUrl, payload);
            }
            return await bytezPost(AIConfig.classificationModel, payload);
        }
        
        // Cache the current audio as a data URL for Bytez (blob: URLs are not accessible to Bytez servers)
        let currentAudioDataUrl = null;
        let currentAudioClipDataUrl = null;
        let currentAudioClipGeneratedAtMs = 0;
        let aiStreamDestination = null;
        const DEFAULT_AI_AUDIO_WINDOW = '15'; // seconds, or 'full'
        const AI_AUDIO_WINDOW_OPTIONS = ['10', '15', '20', '30', '45', '60', 'full'];
        const AI_AUDIO_WINDOW_STORAGE_KEY = 'BYTEZ_AI_AUDIO_WINDOW';
        // Heuristic: if the uploaded file is large, don't attempt full-file base64.
        // Base64 expands ~33% and Bytez has payload limits; we send a short clip instead.
        const AI_FULL_FILE_MAX_BYTES = 6 * 1024 * 1024; // 6 MB
        // Cache for uploaded file URLs (to avoid re-uploading)
        let uploadedFileUrl = null;
        
        /**
         * Upload file to temporary hosting service and get public URL
         * Falls back through multiple services if one fails
         */
        async function uploadFileToTemporaryHost(file) {
            if (!file) return null;
            
            // Try transfer.sh first (simple, no API key needed)
            try {
                const formData = new FormData();
                formData.append('file', file);
                
                const response = await fetch('https://transfer.sh', {
                    method: 'PUT',
                    body: file,
                    headers: {
                        'Max-Downloads': '1',
                        'Max-Days': '1'
                    }
                });
                
                if (response.ok) {
                    const url = (await response.text()).trim();
                    console.log('File uploaded to transfer.sh:', url);
                    return url;
                }
            } catch (error) {
                console.warn('transfer.sh upload failed:', error);
            }
            
            // Fallback: Try file.io (requires POST with file)
            try {
                const formData = new FormData();
                formData.append('file', file);
                
                const response = await fetch('https://file.io', {
                    method: 'POST',
                    body: formData
                });
                
                if (response.ok) {
                    let data = null;
                    try {
                        data = await response.json();
                    } catch (e) {
                        // file.io sometimes returns HTML error pages (starts with '<'), which breaks JSON parsing.
                        let text = '';
                        try { text = await response.text(); } catch {}
                        throw new Error(`file.io returned non-JSON response. ${text ? 'Body: ' + text.slice(0, 180) : ''}`.trim());
                    }
                    if (data.success && data.link) {
                        console.log('File uploaded to file.io:', data.link);
                        return data.link;
                    }
                }
            } catch (error) {
                console.warn('file.io upload failed:', error);
            }
            
            // If both fail, return null (caller should handle)
            return null;
        }
        
        async function getCurrentAudioDataUrl() {
            if (currentAudioDataUrl) return currentAudioDataUrl;
            
            let audioData = null;
            let mimeType = 'audio/mpeg';
            
            if (currentAudioFile) {
                mimeType = currentAudioFile.type || mimeType;
                audioData = await currentAudioFile.arrayBuffer();
            } else if (audioElement?.src && audioElement.src.startsWith('blob:')) {
                const response = await fetch(audioElement.src);
                mimeType = response.headers.get('content-type') || mimeType;
                audioData = await response.arrayBuffer();
            } else if (audioElement?.src && /^https?:\/\//i.test(audioElement.src)) {
                // For remote audio URLs, prefer sending the URL to Bytez (smaller + matches docs).
                // Caller should use `getCurrentAudioBytezAudioContent()` / `getCurrentAudioBytezRequestInput()`.
                return null;
            } else {
                return null;
            }
            
            const audioBlob = new Blob([audioData], { type: mimeType });
            const dataUrl = await new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onerror = () => reject(new Error('Failed to read audio file'));
                reader.onloadend = () => resolve(reader.result);
                reader.readAsDataURL(audioBlob);
            });
            
            currentAudioDataUrl = dataUrl;
            return currentAudioDataUrl;
        }

        function isAudioPlayingNow() {
            return !!(audioElement && !audioElement.paused && !audioElement.ended);
        }

        function canCaptureAudioStream() {
            return !!(audioElement && (typeof audioElement.captureStream === 'function' || (audioContext && mediaSource && typeof audioContext.createMediaStreamDestination === 'function')));
        }

        function getAudioCaptureStream() {
            // Prefer element capture (simple + doesn't require extra graph nodes)
            if (audioElement && typeof audioElement.captureStream === 'function') {
                return audioElement.captureStream();
            }
            // Fallback: tap WebAudio graph via MediaStreamDestination
            if (audioContext && mediaSource && typeof audioContext.createMediaStreamDestination === 'function') {
                if (!aiStreamDestination) {
                    aiStreamDestination = audioContext.createMediaStreamDestination();
                    try {
                        mediaSource.connect(aiStreamDestination);
                    } catch (e) {
                        console.warn('Failed to connect mediaSource to MediaStreamDestination:', e);
                    }
                }
                return aiStreamDestination.stream;
            }
            return null;
        }

        async function blobToDataUrl(blob) {
            return await new Promise((resolve, reject) => {
                const reader = new FileReader();
                reader.onerror = () => reject(new Error('Failed to read recorded audio'));
                reader.onloadend = () => resolve(reader.result);
                reader.readAsDataURL(blob);
            });
        }

        async function getCurrentAudioPreviewClipDataUrl({ seconds = 15, force = false } = {}) {
            // Reuse a recent clip to avoid repeated recording
            if (!force && currentAudioClipDataUrl && (Date.now() - currentAudioClipGeneratedAtMs) < 30_000) {
                return currentAudioClipDataUrl;
            }
            if (!canCaptureAudioStream()) return null;
            if (!isAudioPlayingNow()) return null;

            const stream = getAudioCaptureStream();
            if (!stream) return null;

            if (typeof MediaRecorder === 'undefined') return null;

            const preferredTypes = [
                'audio/webm;codecs=opus',
                'audio/webm',
                'audio/ogg;codecs=opus',
                'audio/ogg'
            ];
            const mimeType = preferredTypes.find(t => MediaRecorder.isTypeSupported(t)) || '';

            const chunks = [];
            const recorder = new MediaRecorder(stream, mimeType ? { mimeType } : undefined);

            const clipPromise = new Promise((resolve, reject) => {
                recorder.ondataavailable = (e) => {
                    if (e.data && e.data.size > 0) chunks.push(e.data);
                };
                recorder.onerror = () => reject(new Error('Audio capture failed'));
                recorder.onstop = async () => {
                    try {
                        const blob = new Blob(chunks, { type: recorder.mimeType || 'audio/webm' });
                        if (!blob || blob.size === 0) return resolve(null);
                        const url = await blobToDataUrl(blob);
                        currentAudioClipDataUrl = url;
                        currentAudioClipGeneratedAtMs = Date.now();
                        resolve(currentAudioClipDataUrl);
                    } catch (err) {
                        reject(err);
                    }
                };
            });

            recorder.start(250);
            setTimeout(() => {
                try { recorder.stop(); } catch {}
            }, Math.max(1000, seconds * 1000));

            return await clipPromise;
        }

        function getAiAudioWindowSetting() {
            const raw = ((Storage.get(AI_AUDIO_WINDOW_STORAGE_KEY) || DEFAULT_AI_AUDIO_WINDOW) + '').trim();
            if (!AI_AUDIO_WINDOW_OPTIONS.includes(raw)) return { mode: 'clip', seconds: parseInt(DEFAULT_AI_AUDIO_WINDOW, 10) };
            if (raw === 'full') return { mode: 'full' };
            const seconds = parseInt(raw, 10);
            return { mode: 'clip', seconds: Number.isFinite(seconds) ? seconds : 15 };
        }

        function setAiAudioWindowSetting(value) {
            const v = String(value || '').trim();
            if (!AI_AUDIO_WINDOW_OPTIONS.includes(v)) return;
            Storage.set(AI_AUDIO_WINDOW_STORAGE_KEY, v);
            // force regenerate clip next time
            currentAudioClipDataUrl = null;
            currentAudioClipGeneratedAtMs = 0;
        }

        function syncAiAudioWindowUi() {
            const setting = getAiAudioWindowSetting();
            const value = setting.mode === 'full' ? 'full' : String(setting.seconds);
            const elUpload = document.getElementById('aiAudioSendModeUpload');
            if (elUpload) elUpload.value = value;
            const elChat = document.getElementById('aiAudioSendModeChat');
            if (elChat) elChat.value = value;
        }

        // Build the audio object in the exact "messages[].content[]" shape Bytez expects.
        // If we have a remote URL, send { type:'audio', url }. Otherwise fall back to { base64 }.
        async function getCurrentAudioBytezAudioContent() {
            // If already a remote URL, use it directly
            if (audioElement?.src && /^https?:\/\//i.test(audioElement.src)) {
                return { type: 'audio', url: audioElement.src };
            }
            
            const setting = getAiAudioWindowSetting();
            if (setting.mode === 'clip') {
                // Clip capture requires playback
                const clip = await getCurrentAudioPreviewClipDataUrl({ seconds: setting.seconds });
                if (clip) return { type: 'audio', base64: clip };
                // If clip capture not possible, fallback to full file handling below
            }

            // For full file: check if it's too large for base64
            if (currentAudioFile && currentAudioFile.size > AI_FULL_FILE_MAX_BYTES) {
                // File is too large for base64 - upload to temporary hosting and use URL
                console.log(`File too large for base64 (${(currentAudioFile.size / 1024 / 1024).toFixed(2)}MB), uploading to temporary host...`);
                
                // Use cached URL if available
                if (uploadedFileUrl) {
                    console.log('Using cached uploaded URL:', uploadedFileUrl);
                    return { type: 'audio', url: uploadedFileUrl };
                }
                
                // Upload file to get public URL
                const publicUrl = await uploadFileToTemporaryHost(currentAudioFile);
                if (publicUrl) {
                    uploadedFileUrl = publicUrl;
                    console.log('File uploaded successfully, using URL instead of base64');
                    return { type: 'audio', url: publicUrl };
                } else {
                    // Upload failed - show error
                    throw new Error('File too large for base64 and temporary upload failed. Please use a clip option (10s-60s) or host the file yourself and provide a URL.');
                }
            }

            // File is small enough for base64
            const audioBase64 = await getCurrentAudioDataUrl();
            if (!audioBase64) return null;
            return { type: 'audio', base64: audioBase64 };
        }

        // Build the top-level request input for models like audio-classification:
        // either { url } or { base64 }.
        async function getCurrentAudioBytezRequestInput() {
            // If already a remote URL, use it directly
            if (audioElement?.src && /^https?:\/\//i.test(audioElement.src)) {
                return { url: audioElement.src };
            }
            
            const setting = getAiAudioWindowSetting();
            if (setting.mode === 'clip') {
                const clip = await getCurrentAudioPreviewClipDataUrl({ seconds: setting.seconds });
                if (clip) return { base64: clip };
                // If clip capture not possible, fallback to full file handling below
            }

            // For full file: check if it's too large for base64
            if (currentAudioFile && currentAudioFile.size > AI_FULL_FILE_MAX_BYTES) {
                // File is too large for base64 - upload to temporary hosting and use URL
                console.log(`File too large for base64 (${(currentAudioFile.size / 1024 / 1024).toFixed(2)}MB), uploading to temporary host...`);
                
                // Use cached URL if available
                if (uploadedFileUrl) {
                    return { url: uploadedFileUrl };
                }
                
                // Upload file to get public URL
                const publicUrl = await uploadFileToTemporaryHost(currentAudioFile);
                if (publicUrl) {
                    uploadedFileUrl = publicUrl;
                    return { url: publicUrl };
                } else {
                    // Upload failed
                    throw new Error('File too large for base64 and temporary upload failed. Please use a clip option (10s-60s) or host the file yourself and provide a URL.');
                }
            }

            // File is small enough for base64
            const audioBase64 = await getCurrentAudioDataUrl();
            if (!audioBase64) return null;
            return { base64: audioBase64 };
        }
        
        // Audio Classification - for genre/category detection
        async function classifyAudio() {
            if (!AIConfig.enabled) return null;
            try {
                const input = await getCurrentAudioBytezRequestInput();
                if (!input) return null;
                
                // Matches Bytez audio-classification example:
                // POST /models/v2/aaraki/wav2vec2-base-finetuned-ks  { url: "..." } OR { base64: "data:audio/...;base64,..." }
                const output = await aiPostClassification(input);
                return Array.isArray(output) ? output : null;
            } catch (error) {
                console.error('Audio classification error:', error);
                updateAIAnalysisDisplayError(`Classification failed: ${error.message}`);
                return null;
            }
        }
        
        // Extract audio features for AI analysis
        function extractAudioFeatures() {
            if (!analyserNode || !frequencyData || !audioElement) {
                return null;
            }
            
            analyserNode.getByteFrequencyData(frequencyData);
            analyserNode.getByteTimeDomainData(timeData);
            
            // Calculate frequency bands
            const bassRange = frequencyData.slice(0, Math.floor(frequencyData.length * 0.1));
            const midRange = frequencyData.slice(Math.floor(frequencyData.length * 0.1), Math.floor(frequencyData.length * 0.5));
            const highRange = frequencyData.slice(Math.floor(frequencyData.length * 0.5));
            
            const bassAvg = bassRange.reduce((a, b) => a + b, 0) / bassRange.length / 255;
            const midAvg = midRange.reduce((a, b) => a + b, 0) / midRange.length / 255;
            const highAvg = highRange.reduce((a, b) => a + b, 0) / highRange.length / 255;
            
            // Calculate overall volume
            const volume = frequencyData.reduce((a, b) => a + b, 0) / frequencyData.length / 255;
            
            // Calculate spectral centroid (brightness)
            let weightedSum = 0;
            let magnitudeSum = 0;
            for (let i = 0; i < frequencyData.length; i++) {
                const magnitude = frequencyData[i] / 255;
                weightedSum += i * magnitude;
                magnitudeSum += magnitude;
            }
            const spectralCentroid = magnitudeSum > 0 ? weightedSum / magnitudeSum : 0;
            
            // Calculate spectral rolloff (frequency below which 85% of energy is contained)
            let cumulativeEnergy = 0;
            const totalEnergy = frequencyData.reduce((a, b) => a + (b / 255), 0);
            let rolloffIndex = 0;
            for (let i = 0; i < frequencyData.length; i++) {
                cumulativeEnergy += frequencyData[i] / 255;
                if (cumulativeEnergy >= totalEnergy * 0.85) {
                    rolloffIndex = i;
                    break;
                }
            }
            
            // Calculate zero crossing rate (roughness/noisiness)
            let zeroCrossings = 0;
            for (let i = 1; i < timeData.length; i++) {
                if ((timeData[i] >= 128 && timeData[i-1] < 128) || 
                    (timeData[i] < 128 && timeData[i-1] >= 128)) {
                    zeroCrossings++;
                }
            }
            const zcr = zeroCrossings / timeData.length;
            
            return {
                bass: bassAvg,
                mid: midAvg,
                high: highAvg,
                volume: volume,
                spectralCentroid: spectralCentroid,
                spectralRolloff: rolloffIndex / frequencyData.length,
                zeroCrossingRate: zcr,
                timestamp: audioElement.currentTime,
                duration: audioElement.duration,
                sampleRate: audioContext.sampleRate
            };
        }
        
        // Store the uploaded audio file for Qwen2-Audio
        let currentAudioFile = null;
        
        // Send audio file to Qwen2-Audio for analysis (Bytez HTTP API)
        async function analyzeWithAI(analysisType = 'general', userPrompt = null) {
            if (!AIConfig.enabled) return null;
            
            // Qwen2-Audio needs the actual audio file, not just features
            if (!currentAudioFile && !audioElement?.src) {
                console.error('No audio file available for analysis');
                return null;
            }
            
            try {
                // Prepare prompt based on analysis type
                let textPrompt = userPrompt || '';
                
                if (!textPrompt) switch(analysisType) {
                    case 'genre':
                        textPrompt = 'Analyze this audio WITHOUT forcing a single genre. Provide 2‚Äì5 plausible genres/styles with confidence estimates (and note uncertainty if it is cross-genre), key cues you used (instrumentation/tempo/texture/vocals), similar artists across those lanes, mood tags, and era/style notes.';
                        break;
                        
                    case 'mood':
                        textPrompt = 'Analyze the mood and emotional characteristics of this audio. Provide: Primary mood, emotional characteristics, intensity level, and psychological effects.';
                        break;
                        
                    case 'technical':
                        textPrompt = 'Analyze the technical characteristics and production quality of this audio. Return ONLY JSON in the following schema:\n{\n  "cards": [\n    {"title": "string", "score": 0-100, "description": "string"}\n  ]\n}\nConstraints: 2‚Äì4 cards, no markdown, no code fences.';
                        break;

                    case 'psychological':
                        textPrompt = 'Psychological analysis of this audio. Do NOT mention ACT or any specific therapy modality. Return ONLY JSON in the following schema:\n{\n  "cards": [\n    {"title": "string", "score": 0-100, "description": "string"}\n  ]\n}\nConstraints: exactly 3 cards, no markdown, no code fences. Keep each description 2‚Äì3 sentences.';
                        break;

                    case 'narrative':
                        textPrompt = 'Narrative analysis of this audio. Return ONLY JSON in the following schema:\n{\n  "cards": [\n    {"title": "string", "score": 0-100, "description": "string"}\n  ]\n}\nConstraints: 2‚Äì3 cards, no markdown, no code fences.';
                        break;

                    case 'cultural':
                        textPrompt = 'Cultural/context analysis of this audio. Return ONLY JSON in the following schema:\n{\n  "cards": [\n    {"title": "string", "score": 0-100, "description": "string"}\n  ]\n}\nConstraints: 2‚Äì3 cards, no markdown, no code fences.';
                        break;

                    case 'gaming':
                        textPrompt = 'Game integration analysis of this audio. Return ONLY JSON in the following schema:\n{\n  "cards": [\n    {"title": "string", "score": 0-100, "description": "string"}\n  ]\n}\nConstraints: 2‚Äì3 cards, no markdown, no code fences.';
                        break;

                    case 'harmony':
                        textPrompt = 'Harmonic analysis: estimate key (with confidence), likely chord loop/progression (if any), and notable harmonic devices. If unsure, say so. Keep it short and practical.';
                        break;
                        
                    default:
                        textPrompt = 'Provide a comprehensive analysis of this audio covering genre, mood, technical characteristics, and production quality.';
                }
                
                // If we have a big local file, let the UI be explicit we're analyzing a short clip
                if (analysisType === 'general') {
                    const setting = getAiAudioWindowSetting();
                    if (setting.mode === 'clip') {
                        setAIAnalysisStatus(`Analyzing a ${setting.seconds}s preview clip‚Ä¶`);
                    } else {
                        setAIAnalysisStatus(`Analyzing the entire track file‚Ä¶`);
                    }
                }

                let audioContent;
                try {
                    audioContent = await getCurrentAudioBytezAudioContent();
                } catch (uploadError) {
                    // Handle upload failures gracefully
                    console.error('Failed to prepare audio content:', uploadError);
                    throw new Error(uploadError.message || 'Failed to prepare audio for analysis. File may be too large.');
                }
                if (!audioContent) {
                    throw new Error('Unable to prepare audio content. Please ensure the file is valid and try using a clip option.');
                }
                
                // Prepare messages for Qwen2-Audio format (as per API docs)
                // Format: messages array with role and content
                const messages = [
                    {
                        role: 'user',
                        content: [
                            {
                                type: 'text',
                                text: textPrompt
                            },
                            audioContent
                        ]
                    }
                ];
                
                // Matches Bytez audio-text-to-text example:
                // POST /models/v2/Qwen/Qwen2-Audio-7B-Instruct { messages: [...] }
                const output = await aiPostChat({
                    messages,
                    stream: false,
                    params: {
                        min_length: 10,
                        max_length: analysisType === 'technical' ? 250 : 200,
                        temperature: 0.5
                    }
                });
                
                // Qwen2-Audio returns { role: 'assistant', content: '...' }
                let analysisText = '';
                if (output) {
                    if (typeof output === 'string') analysisText = output;
                    else if (output.content) analysisText = output.content;
                    else if (output.text) analysisText = output.text;
                    else analysisText = JSON.stringify(output, null, 2);
                } else {
                    analysisText = 'Analysis completed but no output received.';
                }
                
                // Also get features for display
                const features = extractAudioFeatures() || {
                    bass: 0,
                    mid: 0,
                    high: 0,
                    volume: 0
                };
                
                return {
                    type: analysisType,
                    features: features,
                    analysis: analysisText,
                    timestamp: Date.now()
                };
                
            } catch (error) {
                console.error('AI analysis error:', error);
                const errorMessage = error.message || 'Unknown error';
                const isAuthError = /401|403|unauthorized|forbidden/i.test(errorMessage);
                const isTooLarge = /too large|split the file|payload/i.test(errorMessage);

                // One automatic retry: if Bytez says too large, record a short clip and retry.
                if (isTooLarge && isAudioPlayingNow() && canCaptureAudioStream()) {
                    try {
                        const setting = getAiAudioWindowSetting();
                        const seconds = setting.mode === 'clip' ? setting.seconds : 15;
                        setAIAnalysisStatus(`Track too large for AI. Capturing ${seconds}s clip and retrying‚Ä¶`);
                        await getCurrentAudioPreviewClipDataUrl({ force: true, seconds });
                        const retry = await analyzeWithAI(analysisType);
                        if (retry) return retry;
                    } catch (e) {
                        // fall through to error display
                    }
                }

                if (isAuthError) {
                    updateAIAnalysisDisplayError(`API Key Error: ${errorMessage}. Please check your Bytez API key in settings (‚öôÔ∏è button).`);
                } else if (isTooLarge || /upload.*fail|temporary.*fail/i.test(errorMessage)) {
                    updateAIAnalysisDisplayError(`Audio too large for base64. The app attempted to upload to a temporary host, but it failed. Options: 1) Use a clip option (10s-60s), 2) Host the file yourself and provide a URL, or 3) Press play and try again (will capture a clip automatically).`);
                } else {
                    updateAIAnalysisDisplayError(`AI Analysis Error: ${errorMessage}`);
                }
                showError(`AI analysis failed: ${errorMessage}`);
                return null;
            }
        }
        
        // Real-time AI analysis (runs periodically during playback)
        let aiAnalysisInterval = null;
        let lastAIAnalysis = null;
        
        function startAIAnalysis(intervalMs = 5000) {
            if (!AIConfig.enabled) {
                console.log('AI analysis is disabled. Configure AIConfig to enable.');
                return;
            }
            if (!initializeBytez()) {
                updateAIAnalysisDisplayError('AI is not configured. Click ‚öôÔ∏è and paste your Bytez API key.');
                return;
            }
            
            stopAIAnalysis(); // Clear any existing interval

            // Make it explicit what the AI is doing
            setAIAnalysisStatus('Analyzing uploaded track (full file)‚Ä¶');
            
            // Run both classification and chat analysis
            Promise.all([
                // Audio classification for genre/categories
                classifyAudio().then(classification => {
                    if (classification && Array.isArray(classification)) {
                        updateGenreFromClassification(classification);
                    }
                }).catch(error => {
                    console.error('Classification error:', error);
                }),
                // Conversational analysis
                analyzeWithAI('general').then(result => {
                    if (result) {
                        lastAIAnalysis = result;
                        updateAIAnalysisDisplay(result);
                    }
                }).catch(error => {
                    console.error('Chat analysis error:', error);
                })
            ]).catch(error => {
                console.error('AI analysis error:', error);
                updateAIAnalysisDisplayError(`AI analysis failed: ${error.message}`);
            });
            
            // Set up periodic analysis
            aiAnalysisInterval = setInterval(async () => {
                if (audioElement && !audioElement.paused && !audioElement.ended) {
                    const result = await analyzeWithAI('general');
                    if (result) {
                        lastAIAnalysis = result;
                        updateAIAnalysisDisplay(result);
                    }
                }
            }, intervalMs);
        }
        
        function updateGenreFromClassification(classification) {
            // classification is array of {score, label}
            if (!classification || !Array.isArray(classification) || classification.length === 0) {
                return;
            }
            
            // Sort by score (highest first)
            const sorted = classification.sort((a, b) => b.score - a.score);
            const topLabels = sorted.slice(0, 5);
            
            const sidebar = document.getElementById('genreSidebar');
            if (sidebar) {
                sidebar.innerHTML = `
                    <div style="margin-bottom: 15px;">
                        <strong style="color: var(--primary);">Audio Classification:</strong>
                        <div style="margin-top: 10px;">
                            ${topLabels.map((item, idx) => `
                                <div style="display: flex; justify-content: space-between; margin-bottom: 8px; padding: 8px; background: rgba(0, 255, 136, 0.1); border-radius: 5px;">
                                    <span style="color: var(--text-secondary);">${idx + 1}. ${item.label}</span>
                                    <span style="color: var(--primary); font-family: 'JetBrains Mono', monospace;">${(item.score * 100).toFixed(1)}%</span>
                                </div>
                            `).join('')}
                        </div>
                    </div>
                `;
            }
        }
        
        function stopAIAnalysis() {
            if (aiAnalysisInterval) {
                clearInterval(aiAnalysisInterval);
                aiAnalysisInterval = null;
            }
        }
        
        // Update UI with AI analysis results
        function updateAIAnalysisDisplay(result) {
            // Find or create AI analysis panel
            let aiPanel = document.getElementById('aiAnalysisPanel');
            if (!aiPanel) {
                // Create AI panel if it doesn't exist
                const primaryContent = document.querySelector('.primary-content');
                if (primaryContent) {
                    aiPanel = document.createElement('div');
                    aiPanel.id = 'aiAnalysisPanel';
                    aiPanel.className = 'panel';
                    aiPanel.innerHTML = `
                        <div class="panel-header">
                            <div class="panel-title">ü§ñ AI Analysis</div>
                            <button class="help-btn" onclick="showAIConfig()">‚öôÔ∏è</button>
                        </div>
                        <div id="aiAnalysisContent" style="max-height: 400px; overflow-y: auto;">
                            <p style="color: var(--text-secondary);">AI analysis will appear here...</p>
                        </div>
                    `;
                    primaryContent.appendChild(aiPanel);
                }
            }
            
            const content = document.getElementById('aiAnalysisContent');
            if (content) {
                content.innerHTML = `
                    <div style="margin-bottom: 15px;">
                        <div style="font-size: 0.85em; color: var(--text-secondary); margin-bottom: 10px;">
                            Analysis at ${new Date(result.timestamp).toLocaleTimeString()} (uploaded track file)
                        </div>
                        <div style="background: rgba(0, 255, 136, 0.1); padding: 15px; border-radius: 10px; border: 1px solid var(--primary);">
                            <pre style="color: var(--text-primary); font-family: 'JetBrains Mono', monospace; font-size: 0.9em; white-space: pre-wrap; margin: 0;">${result.analysis}</pre>
                        </div>
                    </div>
                    ${result.features ? `
                    <div style="font-size: 0.8em; color: var(--text-secondary); margin-top: 10px;">
                        <strong>Features:</strong> Bass: ${result.features.bass?.toFixed(2) || 'N/A'} | 
                        Mid: ${result.features.mid?.toFixed(2) || 'N/A'} | 
                        High: ${result.features.high?.toFixed(2) || 'N/A'} | 
                        Volume: ${result.features.volume?.toFixed(2) || 'N/A'}
                    </div>
                    ` : ''}
                `;
            }
        }
        
        // Show AI configuration dialog
        function showAIConfig() {
            const currentKey = AIConfig.apiKey ? '***' + AIConfig.apiKey.slice(-4) : 'Not set';
            const key = prompt(`Bytez API Configuration:\n\nAPI Key: ${currentKey}\nClassification Model: ${AIConfig.classificationModel}\nChat Model: ${AIConfig.chatModel}\nEnabled: ${AIConfig.enabled}\n\nGet your key:\nhttps://bytez.com/api/key\n\nPaste your Bytez API key:`, AIConfig.apiKey || '');
            
            if (key !== null && key.trim()) {
                setBytezApiKey(key.trim());
            }
        }

        function getMaskedKey(key) {
            if (!key) return 'Not set';
            const tail = key.slice(-4);
            return `***${tail}`;
        }

        function updateApiKeyUi() {
            const provider = (AIConfig.provider || 'bytez');
            const enabled =
                (provider === 'bytez')
                    ? (!!AIConfig.apiKey && AIConfig.enabled)
                    : (!!AIConfig.customChatUrl && AIConfig.enabled);

            const label =
                enabled
                    ? (provider === 'bytez'
                        ? `AI: enabled (Bytez ${getMaskedKey(AIConfig.apiKey)})`
                        : `AI: enabled (Custom)`)
                    : `AI: disabled (${provider === 'bytez' ? 'Bytez' : 'Custom'})`;

            const statusUpload = document.getElementById('bytezKeyStatusUpload');
            if (statusUpload) statusUpload.textContent = label;
            const statusChat = document.getElementById('bytezKeyStatusChat');
            if (statusChat) statusChat.textContent = label;
        }

        function setBytezApiKey(key) {
            AIConfig.apiKey = (key || '').trim();
            if (AIConfig.apiKey) {
                // If the user is saving a Bytez key, switch provider to Bytez (prevents ‚Äúsaved but still disabled‚Äù confusion).
                AIConfig.provider = 'bytez';
                Storage.set('AI_PROVIDER', 'bytez');

                const okWrite = Storage.set('BYTEZ_KEY', AIConfig.apiKey);
                if (!okWrite) {
                    showError('Could not save API key: browser storage is blocked. Try a normal tab (not private) or serve the page from your website.');
                    // Still keep it in-memory for this session
                }
            } else {
                Storage.remove('BYTEZ_KEY');
            }

            // Reset cached audio (forces re-encode if needed)
            currentAudioDataUrl = null;

            // Update enabled flag + initialize
            AIConfig.enabled = !!AIConfig.apiKey;
            const ok = initializeBytez();
            AIConfig.enabled = ok;
            updateApiKeyUi();

            if (ok) {
                showSuccess('Bytez key saved. AI enabled.');
                const content = document.getElementById('aiAnalysisContent');
                if (content) {
                    content.innerHTML = '<p style="color: var(--text-secondary);">AI is ready. Press play to analyze, or ask a question in chat.</p>';
                }
            } else {
                showError('Failed to enable AI. Check your Bytez key.');
                updateAIAnalysisDisplayError('AI not configured. Paste your Bytez API key above the chat (or click ‚öôÔ∏è).');
            }

            // If a file was selected before AI was enabled, re-enable GO now.
            try { updateGoButtonState(); } catch {}
        }

        function clearBytezApiKey() {
            AIConfig.apiKey = '';
            AIConfig.enabled = false;
            Storage.remove('BYTEZ_KEY');
            currentAudioDataUrl = null;
            updateApiKeyUi();
            showSuccess('Bytez key cleared. AI disabled.');
            try { updateGoButtonState(); } catch {}
        }

        // Quick key verification without uploading audio.
        // This intentionally sends a tiny request that may return a payload error, but verifies auth + connectivity.
        async function testBytezKey(key) {
            const k = (key || AIConfig.apiKey || '').trim();
            if (!k) {
                showError('Paste a Bytez API key first.');
                return false;
            }

            const statusUpload = document.getElementById('bytezKeyStatusUpload');
            const statusChat = document.getElementById('bytezKeyStatusChat');
            const prevUpload = statusUpload?.textContent;
            const prevChat = statusChat?.textContent;
            if (statusUpload) statusUpload.textContent = 'AI: testing‚Ä¶';
            if (statusChat) statusChat.textContent = 'AI: testing‚Ä¶';

            try {
                const res = await fetch(`https://api.bytez.com/models/v2/${AIConfig.classificationModel}`, {
                    method: 'POST',
                    headers: {
                        'Authorization': getBytezAuthorizationHeaderValue(k),
                        'Content-Type': 'application/json'
                    },
                    // Intentionally invalid URL so the request is tiny.
                    body: JSON.stringify({ url: 'https://example.com/does-not-exist.wav' })
                });

                if (res.status === 401 || res.status === 403) {
                    showError('Bytez key rejected (401/403). Double-check the key.');
                    return false;
                }

                // For our purposes, any non-401/403 response means the key is at least accepted / service reachable.
                if (res.ok) {
                    showSuccess('Bytez key looks valid (request accepted).');
                    return true;
                }

                // Many ‚Äúexpected‚Äù errors here mean auth is OK but payload is bad.
                if ([400, 404, 415, 422].includes(res.status)) {
                    showSuccess(`Bytez key looks valid (auth ok). Server responded HTTP ${res.status}.`);
                    return true;
                }

                const text = await res.text().catch(() => '');
                showError(`Bytez test returned HTTP ${res.status}. ${text ? String(text).slice(0, 160) : ''}`.trim());
                return false;
            } catch (e) {
                showError(`Bytez test failed: ${e?.message || String(e)}`);
                return false;
            } finally {
                // Restore whatever the UI state is based on saved config.
                updateApiKeyUi();
                if (statusUpload && prevUpload && statusUpload.textContent === 'AI: testing‚Ä¶') statusUpload.textContent = prevUpload;
                if (statusChat && prevChat && statusChat.textContent === 'AI: testing‚Ä¶') statusChat.textContent = prevChat;
            }
        }
        
        // Update AI Analysis Display with Error
        function updateAIAnalysisDisplayError(message) {
            let aiPanel = document.getElementById('aiAnalysisPanel');
            if (!aiPanel) {
                // Create AI panel if it doesn't exist
                const sidebar = document.querySelector('.sidebar');
                if (sidebar) {
                    aiPanel = document.createElement('div');
                    aiPanel.id = 'aiAnalysisPanel';
                    aiPanel.className = 'panel';
                    aiPanel.innerHTML = `
                        <div class="panel-header">
                            <div class="panel-title">ü§ñ AI Analysis</div>
                            <button class="help-btn" onclick="showAIConfig()">‚öôÔ∏è</button>
                        </div>
                        <div id="aiAnalysisContent" style="max-height: 400px; overflow-y: auto;">
                            <p style="color: var(--text-secondary);">AI analysis will appear here...</p>
                        </div>
                    `;
                    sidebar.insertBefore(aiPanel, sidebar.firstChild);
                }
            }
            
            const content = document.getElementById('aiAnalysisContent');
            if (content) {
                content.innerHTML = `
                    <div style="padding: 15px; background: rgba(255, 107, 107, 0.1); border-radius: 5px; border: 1px solid rgba(255, 107, 107, 0.3);">
                        <strong style="color: var(--accent);">‚ö†Ô∏è AI Analysis Error</strong>
                        <p style="color: var(--text-secondary); margin-top: 10px; line-height: 1.6;">
                            ${message}
                        </p>
                        <p style="color: var(--text-secondary); margin-top: 10px; font-size: 0.9em;">
                            Click the ‚öôÔ∏è button above to configure your Bytez API key.
                        </p>
                    </div>
                `;
            }
        }

        function setAIAnalysisStatus(message) {
            let aiPanel = document.getElementById('aiAnalysisPanel');
            if (!aiPanel) return;

            const content = document.getElementById('aiAnalysisContent');
            if (!content) return;

            content.innerHTML = `
                <div style="padding: 12px; background: rgba(0, 136, 255, 0.10); border-radius: 8px; border: 1px solid rgba(0, 136, 255, 0.25);">
                    <div style="color: var(--text-primary); font-weight: 700; margin-bottom: 6px;">${message}</div>
                    <div style="color: var(--text-secondary); font-size: 0.85em; line-height: 1.4;">
                        Note: this sends the uploaded audio file (or URL) to the AI service ‚Äî it is not listening to your live system audio.
                    </div>
                </div>
            `;
        }
        
        // ============================================
        // AI Conversation Functions
        // ============================================
        function sendMessage() {
            const input = document.getElementById('chatInput');
            const message = input.value.trim();
            if (!message) return;
            
            addUserMessage(message);
            input.value = '';
            
            if (!AIConfig.enabled) {
                addAIMessage('AI is not configured yet. Click ‚öôÔ∏è and paste your Bytez API key.');
                return;
            }
            
            // Real AI response via Qwen2-Audio
            addAIMessage('Analyzing the uploaded track + your question‚Ä¶');
            const history = document.getElementById('conversationHistory');
            const thinkingNode = history?.lastElementChild;
            
            (async () => {
                const audioContent = await getCurrentAudioBytezAudioContent();
                if (!audioContent) throw new Error('No audio loaded');
                
                const messages = [
                    {
                        role: 'user',
                        content: [
                            { type: 'text', text: message },
                            audioContent
                        ]
                    }
                ];
                
                const output = await aiPostChat({
                    messages,
                    stream: false,
                    params: {
                        min_length: 10,
                        max_length: 200,
                        temperature: 0.5
                    }
                });
                
                const text =
                    (typeof output === 'string')
                        ? output
                        : (output?.content || output?.text || JSON.stringify(output, null, 2));
                
                if (thinkingNode && thinkingNode.classList.contains('message') && thinkingNode.classList.contains('ai')) {
                    thinkingNode.innerHTML = `<div class="message-content">${text}</div>`;
                } else {
                    addAIMessage(text);
                }
            })().catch(err => {
                const msg = `AI error: ${err.message}`;
                if (thinkingNode && thinkingNode.classList.contains('message') && thinkingNode.classList.contains('ai')) {
                    thinkingNode.innerHTML = `<div class="message-content">${msg}</div>`;
                } else {
                    addAIMessage(msg);
                }
                updateAIAnalysisDisplayError(msg);
            });
        }
        
        function addUserMessage(message) {
            const history = document.getElementById('conversationHistory');
            const messageDiv = document.createElement('div');
            messageDiv.className = 'message user';
            messageDiv.innerHTML = `<div class="message-content">${message}</div>`;
            history.appendChild(messageDiv);
            history.scrollTop = history.scrollHeight;
            
            conversationHistory.push({ type: 'user', message });
        }
        
        function addAIMessage(message) {
            const history = document.getElementById('conversationHistory');
            const messageDiv = document.createElement('div');
            messageDiv.className = 'message ai';
            messageDiv.innerHTML = `<div class="message-content">${message}</div>`;
            history.appendChild(messageDiv);
            history.scrollTop = history.scrollHeight;
            
            conversationHistory.push({ type: 'ai', message });
        }
        
        // Utility functions
        function showError(message) {
            const errorDiv = document.createElement('div');
            errorDiv.className = 'error';
            errorDiv.textContent = message;
            document.body.appendChild(errorDiv);
            setTimeout(() => errorDiv.remove(), 5000);
        }
        
        function showSuccess(message) {
            const successDiv = document.createElement('div');
            successDiv.className = 'success';
            successDiv.textContent = message;
            document.body.appendChild(successDiv);
            setTimeout(() => successDiv.remove(), 3000);
        }
        
        // Audio context resume
        document.addEventListener('click', async function resumeAudioContext() {
            if (audioContext && audioContext.state === 'suspended') {
                console.log('User clicked - attempting to resume audio context');
                try {
                    await audioContext.resume();
                    console.log('Audio context resumed successfully, state:', audioContext.state);
                    showSuccess('Audio analysis ready!');
                } catch (error) {
                    console.error('Failed to resume audio context:', error);
                    showError('Failed to initialize audio analysis');
                }
            }
        });
        
        // Add visual feedback for audio context state
        function checkAudioContextState() {
            if (audioContext) {
                if (audioContext.state === 'suspended') {
                    updatePowerupResults('‚è∏Ô∏è Audio analysis paused - click anywhere to activate');
                } else if (audioContext.state === 'running') {
                    updatePowerupResults('‚úÖ Audio analysis ready - upload a file and press play');
                }
            }
        }
        
        // Check audio context state periodically
        setInterval(checkAudioContextState, 2000);
        
        // Handle window resize
        window.addEventListener('resize', resizeCanvases);
        
        // Cleanup
        window.addEventListener('beforeunload', () => {
            Object.values(animationFrames).forEach(frame => {
                if (frame) cancelAnimationFrame(frame);
            });
        });
    </script>
</body>
</html>